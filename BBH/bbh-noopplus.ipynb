{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Setup model connection\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv(\"../.env\")\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"VLLM_API_KEY\"),\n",
    "    base_url=\"http://134.76.18.30:8085/v1\"\n",
    ")\n",
    "model = \"meta-llama/Llama-3.1-8B-Instruct\""
   ],
   "id": "16d98249b3167ea9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load original dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d57750e572255fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_subsets(dataset_name: str) -> list:\n",
    "    import requests\n",
    "    headers = {\"Authorization\": f\"Bearer {os.getenv('HF_TOKEN')}\"}\n",
    "    API_URL = f\"https://datasets-server.huggingface.co/splits?dataset={dataset_name}\"\n",
    "    data = requests.get(API_URL, headers=headers).json()\n",
    "    return data[\"splits\"]"
   ],
   "id": "6214f9abed31c1eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "get_subsets(\"maveriq/bigbenchhard\")",
   "id": "9ce9082798edfb19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pprint import pprint\n",
    "\n",
    "import pandas\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from datasets import load_dataset, Dataset, DatasetDict, concatenate_datasets\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load spaCy for POS tagging\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "tqdm.pandas()\n",
    "\n",
    "selected_subset = \"train\"\n",
    "dataset_name = \"maveriq/bigbenchhard\"\n",
    "modified_dataset_name = \"BBH-NoOp-Plus\"\n",
    "\n",
    "hf_username = \"LFrancis\"\n",
    "repo_id = f\"{hf_username}/{modified_dataset_name}\"\n",
    "\n",
    "dataset_dict = DatasetDict()\n",
    "subjects = get_subsets(dataset_name)\n",
    "\n",
    "dataset = load_dataset(dataset_name, \"all\")[selected_subset]\n",
    "df = pd.DataFrame(dataset)\n",
    "for subject in subjects:\n",
    "    subject_df = df[df['subject'] == subject].reset_index(drop=True)\n",
    "    subject_dataset = Dataset.from_pandas(subject_df)\n",
    "    dataset_dict[subject] = subject_dataset\n",
    "dataset_dict[\"all\"] = Dataset.from_pandas(df)\n",
    "example_question = \"How can one differentiate a set and a dictionary in python?\"\n",
    "dataset_dict"
   ],
   "id": "7b4fe193ef4b75e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def calculate_all(suffix: str):\n",
    "    if \"all_\"+suffix in list(dataset_dict.keys()):\n",
    "        del dataset_dict[\"all_\"+suffix]\n",
    "    all_datasets = []\n",
    "    for key in dataset_dict.keys():\n",
    "        if key.split(\"_\")[-1] == suffix:\n",
    "            all_datasets.append(dataset_dict[key])\n",
    "    all_naive = concatenate_datasets(all_datasets)\n",
    "    dataset_dict[\"all_\"+suffix] = all_naive\n",
    "    print(len(dataset_dict[\"all_\"+suffix]))\n",
    "    pprint(dataset_dict.keys())"
   ],
   "id": "45aa528126d0bb1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8f7a1ffd1509f748",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "## Paraphrase Type: Naive Addition",
   "id": "e2d4da176f5705ba"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "code",
   "source": [
    "def add_sentence_to_question(question: str) -> str:\n",
    "    return question + \" \" + \"Sebastian goes to buy icecream.\"\n",
    "\n",
    "\n",
    "print(\"Rows mentioning 'Sebastian':\", len(df[df['question'].str.contains(\"Sebastian\")]))\n",
    "print(\"Rows mentioning 'icecream':\", len(df[df['question'].str.contains(\"icecream\")]))\n",
    "add_sentence_to_question(example_question)"
   ],
   "id": "5a6a869abf2d97c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def add_naive_sentence(row):\n",
    "    row[\"question\"] = add_sentence_to_question(row[\"question\"])\n",
    "    return row\n",
    "\n",
    "for subject in subjects:\n",
    "    df_naive = pd.DataFrame(dataset_dict[subject])\n",
    "    df_naive = df_naive.progress_apply(add_naive_sentence, axis=1)\n",
    "    dataset_naive = Dataset.from_pandas(df_naive)\n",
    "    dataset_dict[subject + \"_naive\"] = dataset_naive\n",
    "pprint(list(dataset_dict.keys()))"
   ],
   "id": "2db48b93821d5294",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "calculate_all(\"naive\")",
   "id": "fd5b7cb650df7949",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "upload(dataset_dict, repo_id)",
   "id": "acc9a7a357a4e62f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Paraphrase Type: Addition",
   "id": "6f70d4a9110a3bab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "preprompt = \"Give me one additional sentence to this question that has no direct effect on the question. The sentence should be about a similar topic. It should not be a question. Example additional sentences might focus on unnecessary details, add unnecessary information about other fields of study. Only output exactly the additional sentence and nothing else, the output will be copy/pasted as is. It is extremely important that the sentence does not effect the answer to the question.\"\n",
    "\n",
    "addition_prompt = lambda question: str(preprompt + f\"\\nQuestion: \\n'{question}'\\nAdditional sentence:\")\n",
    "\n",
    "def add_additional_information(narrative: str) -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": addition_prompt(narrative),\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-4o\",\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    return narrative + \" \" + result\n",
    "\n",
    "add_additional_information(example_question)"
   ],
   "id": "280023f311f0c678",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def add_additional_sentence(row):\n",
    "    row[\"question\"] = add_additional_information(row[\"question\"])\n",
    "    return row\n",
    "\n",
    "for subject in subjects:\n",
    "    df_additional = pd.DataFrame(dataset_dict[subject])\n",
    "    df_additional = df_additional.progress_apply(add_additional_sentence, axis=1)\n",
    "    dataset_additional = Dataset.from_pandas(df_additional)\n",
    "    dataset_dict[subject + \"_addition\"] = dataset_additional\n",
    "pprint(list(dataset_dict.keys()))"
   ],
   "id": "153c4cdf0b316da4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "calculate_all(\"addition\")",
   "id": "1d27eb6c13b28fa1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "upload(dataset_dict, repo_id)",
   "id": "bca5666b17c6e3f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Paraphrase Type: Lexicon-Changes\n",
   "id": "3af5f01884e9f923"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def fetch_alternative(blanked, original_word):\n",
    "    prompt = f\"Output exactly one word that fits where the placeholder '<BLANK>' is placed and has similar meaning to '{original_word}'. No other output besides the word.\\nText: '{''.join(blanked)}'\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"asdasd\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=5,\n",
    "        top_logprobs=5,\n",
    "        logprobs=True,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    choice = response.choices[0]\n",
    "    if choice.logprobs.content[0].logprob >= -1:\n",
    "        return choice.message.content.lower().strip().replace(\".\", \"\")\n",
    "    return original_word\n",
    "\n",
    "\n",
    "def paraphrase_with_second_best_threading(text):\n",
    "    doc = nlp(text)\n",
    "    words = [token.text_with_ws for token in doc]\n",
    "    pos_tags = [token.pos_ for token in doc]\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for i, pos in enumerate(pos_tags):\n",
    "            if pos == \"ADJ\":\n",
    "                blanked = words.copy()\n",
    "                blanked[i] = \"<BLANK>\"\n",
    "                future = executor.submit(fetch_alternative, blanked, words[i])\n",
    "                futures.append((i, future))\n",
    "\n",
    "        for i, future in futures:\n",
    "            alt = future.result()\n",
    "            if alt != words[i]:\n",
    "                words[i] = alt + doc[i].whitespace_\n",
    "\n",
    "    return \"\".join(words)\n",
    "\n",
    "\n",
    "story = \"Once upon a time, there was a brave knight who fought dragons.\"\n",
    "\n",
    "# Get the paraphrased story\n",
    "paraphrased_story = paraphrase_with_second_best_threading(story)\n",
    "print(\"Original Story:\", story)\n",
    "print(\"Paraphrased Story:\", paraphrased_story)\n"
   ],
   "id": "2084900e4d7c12c3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def paraphrase_single_words(row):\n",
    "    row[\"question\"] = paraphrase_with_second_best_threading(row[\"question\"])\n",
    "    return row\n",
    "\n",
    "\n",
    "for subject in subjects:\n",
    "    df_lex = pd.DataFrame(dataset_dict[subject])\n",
    "    df_lex = df_lex.progress_apply(paraphrase_single_words, axis=1)\n",
    "    dataset_lex = Dataset.from_pandas(df_lex)\n",
    "    dataset_dict[subject + \"_lexicon\"] = dataset_lex\n",
    "\n",
    "dataset_dict.keys()"
   ],
   "id": "d0b5d00a4ba54e62",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "calculate_all(\"lexicon\")",
   "id": "f9b8b02911598544",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "upload(dataset_dict, repo_id)",
   "id": "e4844f39cdde23bd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Paraphrase Type: Syntax-Changes\n",
   "id": "9311a162e96e675"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def rephrase_sentence(sentence):\n",
    "    # Parse the sentence\n",
    "    doc = nlp(sentence)\n",
    "    proper_nouns = {token.text.lower() for token in doc if token.pos_ == \"PROPN\" or token.ent_type_}\n",
    "\n",
    "    # Example: Moving adverbs to the beginning\n",
    "    words = []\n",
    "    adverbs = []\n",
    "\n",
    "    # Split ADV from sentence\n",
    "    for token in doc:\n",
    "        word = token.text_with_ws.capitalize() if token.text.lower() in proper_nouns else token.text_with_ws.lower()\n",
    "        if token.pos_ == \"ADV\":  # Identify adverbs\n",
    "            adverbs.append(word)\n",
    "        else:\n",
    "            words.append(word)\n",
    "\n",
    "    reordered = \"\".join(adverbs + words)\n",
    "    # Capitalize the first word of the sentence\n",
    "    if reordered:\n",
    "        reordered = reordered[0].upper() + reordered[1:]\n",
    "\n",
    "    return reordered\n",
    "\n",
    "# Test the function\n",
    "sentence = \"Alice quickly ran to the store in New York.\"\n",
    "rephrased = rephrase_sentence(sentence)\n",
    "print(\"Original:\", sentence)\n",
    "print(\"Rephrased:\", rephrased)"
   ],
   "id": "ca7fd34807441668",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Example paragraph\n",
    "paragraph = \"\"\"Because it was raining, she stayed indoors. The weather had been unpredictable all week.\n",
    "She decided to read a book, hoping the rain would stop. By evening, the sun came out.\n",
    "\"\"\"\n",
    "\n",
    "def split_paragraph_into_sentences(paragraph):\n",
    "    doc = nlp(paragraph)\n",
    "    sentences = [sent.text for sent in doc.sents]\n",
    "    return sentences\n",
    "\n",
    "# Split paragraph into sentences\n",
    "sentences = split_paragraph_into_sentences(paragraph)\n",
    "\n",
    "# Print the sentences\n",
    "for sentence in sentences:\n",
    "    print(\"#\",sentence)\n"
   ],
   "id": "3f1999fd1f5a43c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def rephrase_narrative(row):\n",
    "    row[\"question\"] = \"\".join([rephrase_sentence(sentence) for sentence in split_paragraph_into_sentences(row[\"question\"])])\n",
    "    return row\n",
    "\n",
    "\n",
    "for subject in subjects:\n",
    "    df_syn = pd.DataFrame(dataset_dict[subject])\n",
    "    df_syn = df_syn.progress_apply(rephrase_narrative, axis=1)\n",
    "    dataset_syn = Dataset.from_pandas(df_syn)\n",
    "    dataset_dict[subject + \"_syntax\"] = dataset_syn\n",
    "\n",
    "dataset_dict.keys()"
   ],
   "id": "5d1018e2aa2bb754",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "calculate_all(\"syntax\")",
   "id": "59edc08b3ec06f40",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "upload(dataset_dict, repo_id)",
   "id": "4f75e9dd4f309d4a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
