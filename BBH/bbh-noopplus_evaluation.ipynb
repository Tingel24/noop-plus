{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T10:16:08.052041Z",
     "start_time": "2025-01-23T10:16:08.047455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_subsets(dataset_name: str) -> list[str]:\n",
    "    import requests\n",
    "    headers = {\"Authorization\": f\"Bearer {os.getenv('HF_TOKEN')}\"}\n",
    "    API_URL = f\"https://datasets-server.huggingface.co/splits?dataset={dataset_name}\"\n",
    "    data = requests.get(API_URL, headers=headers).json()\n",
    "    return [subset[\"config\"] for subset in data[\"splits\"]]"
   ],
   "id": "6fd90101bea0b2c2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T10:16:08.057013Z",
     "start_time": "2025-01-23T10:16:08.054941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "choice_subsets = [\n",
    "    \"boolean_expressions\",\n",
    "    \"causal_judgement\",\n",
    "    \"date_understanding\",\n",
    "    \"disambiguation_qa\",\n",
    "    \"formal_fallacies\",\n",
    "    \"geometric_shapes\",\n",
    "    \"hyperbaton\",\n",
    "    \"logical_deduction_five_objects\",\n",
    "    \"logical_deduction_seven_objects\",\n",
    "    \"logical_deduction_three_objects\",\n",
    "    \"movie_recommendation\",\n",
    "    \"navigate\",\n",
    "    \"penguins_in_a_table\",\n",
    "    \"reasoning_about_colored_objects\",\n",
    "    \"ruin_names\",\n",
    "    \"salient_translation_error_detection\",\n",
    "    \"salient_translation_error_detection\",\n",
    "    \"snarks\",\n",
    "    \"sports_understanding\",\n",
    "    \"temporal_sequences\",\n",
    "    \"tracking_shuffled_objects_five_objects\",\n",
    "    \"tracking_shuffled_objects_seven_objects\",\n",
    "    \"tracking_shuffled_objects_three_objects\",\n",
    "    \"web_of_lies\"\n",
    "]\n",
    "# Subsets that do not follow the choice paradigm are ignored\n",
    "other_subsets = [\n",
    "    \"dyck_languages\",\n",
    "    \"multistep_arithmetic_two\",\n",
    "    \"object_counting\",\n",
    "    \"word_sorting\"\n",
    "]"
   ],
   "id": "481d06d7239c2ea3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T10:16:10.587337Z",
     "start_time": "2025-01-23T10:16:09.847841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "\n",
    "def preprocess(dataset_name, subset):\n",
    "    dataset = load_dataset(dataset_name, subset)[\"train\"]\n",
    "    choices = list(set(dataset['target']))\n",
    "    dataset = dataset.add_column(\"choices\", [choices] * len(dataset))\n",
    "    dataset = dataset.add_column(\"subset\", [subset] * len(dataset))\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def create_dataset_from_subsets(split, dataset_name):\n",
    "    # split is noop subset, like lexicon, syntax etc\n",
    "    datasets = [preprocess(dataset_name, subset + ((\"_\" + split) if not split == \"\" else \"\")) for subset in\n",
    "                choice_subsets]\n",
    "\n",
    "    return concatenate_datasets(datasets)"
   ],
   "id": "6577e93332295de",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T10:16:49.242629Z",
     "start_time": "2025-01-23T10:16:11.526592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os.path\n",
    "\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\")\n",
    "# Load GSM8k Dataset\n",
    "dataset_name = \"LFrancis/BBH-NoOp-Plus\"\n",
    "baseline_dataset_name = \"maveriq/bigbenchhard\"\n",
    "subset = \"scramble\"\n",
    "dataset = create_dataset_from_subsets(subset, dataset_name)\n",
    "\n",
    "# VLLM API Configuration\n",
    "BASE_URL = \"http://134.76.18.30:8081/v1/chat/completions\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\", \"Authorization\": \"Bearer \" + os.getenv(\"VLLM_API_KEY\")}\n",
    "MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "EVALUATED_MODEL_PATH = dataset_name + \"_\" + subset + \"_evaluated_\" + MODEL_NAME\n",
    "BASELINE_MODEL_PATH = baseline_dataset_name + \"_evaluated_\" + MODEL_NAME\n",
    "if not os.path.exists(EVALUATED_MODEL_PATH):\n",
    "    dataset.save_to_disk(EVALUATED_MODEL_PATH)\n",
    "if not os.path.exists(BASELINE_MODEL_PATH):\n",
    "    baseline_dataset = create_dataset_from_subsets(\"\", baseline_dataset_name)\n",
    "    baseline_dataset.save_to_disk(BASELINE_MODEL_PATH)"
   ],
   "id": "62b73412d8b897a7",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for subset in get_subsets(baseline_dataset_name):\n",
    "    if subset not in choice_subsets and subset not in other_subsets:\n",
    "        print(subset)  # Check if all subsets are accounted for"
   ],
   "id": "e4458dcbfdcc8013",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T10:16:54.893008Z",
     "start_time": "2025-01-23T10:16:54.881896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import Dataset\n",
    "import requests\n",
    "\n",
    "\n",
    "# Helper Functions\n",
    "def create_chat_messages(question, sys_msg):\n",
    "    \"\"\"\n",
    "    Create a formatted list of chat messages for the chat model.\n",
    "    \"\"\"\n",
    "    user_prompt = f\"Q: ${question}\\nA: Let's think step by step.\"\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": sys_msg},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "\n",
    "def query_vllm_api(payload):\n",
    "    \"\"\"\n",
    "    Send a query to the VLLM API and return the response.\n",
    "    \"\"\"\n",
    "    response = requests.post(BASE_URL, json=payload, headers=HEADERS, timeout=120)\n",
    "    response.raise_for_status()  # Raise an error for HTTP issues\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def evaluate_question(entry):\n",
    "    # Step 1: Generate reasoning (CoT) response\n",
    "    sys_msg = \"\"\n",
    "    question = entry[\"input\"]\n",
    "    messages = create_chat_messages(question, sys_msg)\n",
    "\n",
    "    cot_payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 200,\n",
    "        \"temperature\": 0.0,\n",
    "    }\n",
    "\n",
    "    cot_response = query_vllm_api(cot_payload)\n",
    "    if \"object\" in cot_response.keys() and cot_response[\"object\"] == \"error\":\n",
    "        raise Exception(cot_response[\"message\"])\n",
    "\n",
    "    cot_text = cot_response[\"choices\"][0][\"message\"][\"content\"].strip()  # Extract CoT reasoning\n",
    "\n",
    "    # Step 2: Calculate logprobs for each choice\n",
    "    final_prompt = f\"Only output your answer, no other explanation or addition. the answer will be copy/pasted as is. Only output one of the following choices as the final Answer:\\nChoices: {entry['choices']}\\nFinal Answer: \"\n",
    "    choice_messages = [\n",
    "        *messages,\n",
    "        {\"role\": \"system\", \"content\": cot_text},\n",
    "        {\"role\": \"user\", \"content\": final_prompt}\n",
    "    ]\n",
    "    final_payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": choice_messages,\n",
    "        \"max_tokens\": 10,\n",
    "        \"temperature\": 0.0,\n",
    "        \"stop\": [\"\\n\"],\n",
    "    }\n",
    "    final_response = query_vllm_api(final_payload)\n",
    "    gen_answer = final_response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    entry[\"generated_answer\"] = gen_answer\n",
    "    entry[\"generated_cot\"] = cot_text\n",
    "    return entry\n",
    "\n",
    "\n",
    "def is_correct(entry):\n",
    "    \"\"\"\n",
    "    Determines if the choice with the lowest log probability corresponds to the correct answer.\n",
    "\n",
    "    Args:\n",
    "        entry (dict): A dictionary containing the question, choices, answer index, and logprobs.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the option with the lowest logprob matches the correct answer index, False otherwise.\n",
    "    \"\"\"\n",
    "    # Extract logprobs and the correct answer index\n",
    "    gen_answer = entry['generated_answer']\n",
    "    if gen_answer is None:\n",
    "        return False\n",
    "    answer = entry['target']\n",
    "\n",
    "    return answer == gen_answer\n",
    "\n",
    "\n",
    "def process_dataset(dataset: Dataset, numproc=1):\n",
    "    \"\"\"\n",
    "    Process the dataset using Dataset.map.\n",
    "    \"\"\"\n",
    "\n",
    "    def process_entry(entry):\n",
    "        if \"generated_answer\" in entry.keys() and entry[\"generated_answer\"] is not None:\n",
    "            return entry\n",
    "        try:\n",
    "            return evaluate_question(entry)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing entry: {entry}, Exception: {e}\")\n",
    "            entry[\"generated_answer\"] = None\n",
    "            entry[\"generated_cot\"] = None\n",
    "            return entry\n",
    "\n",
    "    return dataset.map(process_entry, with_indices=False, num_proc=numproc)"
   ],
   "id": "c60fc0802c475748",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T10:16:56.166526Z",
     "start_time": "2025-01-23T10:16:56.162528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def update_dataset(dataset, is_baseline=False):\n",
    "    # Save the updated dataset to a temporary location\n",
    "    temp_path = \"temp\"\n",
    "    dataset.save_to_disk(temp_path)\n",
    "\n",
    "    # Overwrite the original dataset directory\n",
    "    import shutil\n",
    "    original_path = EVALUATED_MODEL_PATH if is_baseline == False else BASELINE_MODEL_PATH\n",
    "\n",
    "    # Remove the old dataset and replace it with the new one\n",
    "    shutil.rmtree(original_path)  # Remove the old dataset directory\n",
    "    shutil.move(temp_path, original_path)"
   ],
   "id": "e0ee2b6c396f28dd",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def main(is_continue=False, is_baseline=False, numproc=1):\n",
    "    \"\"\"\n",
    "    Main function to evaluate the dataset asynchronously.\n",
    "    \"\"\"\n",
    "    if is_baseline:\n",
    "        selected_dataset = load_from_disk(BASELINE_MODEL_PATH)\n",
    "    elif is_continue:\n",
    "        selected_dataset = load_from_disk(EVALUATED_MODEL_PATH)\n",
    "    else:\n",
    "        selected_dataset = dataset\n",
    "    # Process the dataset asynchronously\n",
    "    processed_dataset = process_dataset(selected_dataset, numproc)\n",
    "\n",
    "    # Save the updated dataset\n",
    "    update_dataset(processed_dataset, is_baseline)\n",
    "\n",
    "\n",
    "# Run the script\n",
    "main(True, False, 100)"
   ],
   "id": "6c05b4e127512852",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T10:17:00.260533Z",
     "start_time": "2025-01-23T10:16:59.392945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from converter.converter import save_value_to_json\n",
    "\n",
    "for subset in [\"addition\", \"lexicon\", \"syntax\", \"\", \"naive\", \"typo\", \"scramble\"]:\n",
    "    if subset == \"\":\n",
    "        EVALUATED_MODEL_PATH = dataset_name + \"_evaluated_\" + MODEL_NAME\n",
    "        subset = \"our_baseline\"\n",
    "    else:\n",
    "        EVALUATED_MODEL_PATH = dataset_name + \"_\" + subset + \"_evaluated_\" + MODEL_NAME\n",
    "    if os.path.exists(EVALUATED_MODEL_PATH):\n",
    "        selected_dataset = load_from_disk(EVALUATED_MODEL_PATH)\n",
    "        print(selected_dataset)\n",
    "        score = [is_correct(result) for result in selected_dataset]\n",
    "        score = sum(score) / len(score)\n",
    "        save_value_to_json(subset, score, MODEL_NAME)\n",
    "        print(subset, \"accuracy\", score)\n",
    "    else:\n",
    "        print(\"skipping\", EVALUATED_MODEL_PATH)"
   ],
   "id": "d6511a8a3f86cbc0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping LFrancis/BBH-NoOp-Plus_addition_evaluated_meta-llama/Llama-3.1-8B-Instruct\n",
      "Dataset({\n",
      "    features: ['input', 'target', 'choices', 'subset', 'generated_answer', 'generated_cot'],\n",
      "    num_rows: 5761\n",
      "})\n",
      "lexicon accuracy 0.5551119597292137\n",
      "Dataset({\n",
      "    features: ['input', 'target', 'choices', 'subset', 'generated_answer', 'generated_cot'],\n",
      "    num_rows: 5761\n",
      "})\n",
      "syntax accuracy 0.5653532372851935\n",
      "skipping LFrancis/BBH-NoOp-Plus_evaluated_meta-llama/Llama-3.1-8B-Instruct\n",
      "Dataset({\n",
      "    features: ['input', 'target', 'choices', 'subset', 'generated_answer', 'generated_cot'],\n",
      "    num_rows: 5761\n",
      "})\n",
      "naive accuracy 0.5926054504426315\n",
      "Dataset({\n",
      "    features: ['input', 'target', 'choices', 'subset', 'generated_answer', 'generated_cot'],\n",
      "    num_rows: 5761\n",
      "})\n",
      "typo accuracy 0.49210206561360875\n",
      "Dataset({\n",
      "    features: ['input', 'target', 'choices', 'subset', 'generated_answer', 'generated_cot'],\n",
      "    num_rows: 5761\n",
      "})\n",
      "scramble accuracy 0.4106925880923451\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T10:17:06.705015Z",
     "start_time": "2025-01-23T10:17:06.516519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "baseline_dataset = load_from_disk(BASELINE_MODEL_PATH)\n",
    "score = [is_correct(result) for result in baseline_dataset]\n",
    "score = sum(score) / len(score)\n",
    "save_value_to_json(\"baseline\", score, MODEL_NAME)\n",
    "print(\"Baseline Accuracy\", score)"
   ],
   "id": "57d06cdc2ef4c6ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy 0.616906787016143\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "425570df70200025",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
