{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Load original dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d57750e572255fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:57:13.484676Z",
     "start_time": "2025-01-06T12:57:10.825220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from datasets import load_dataset, Dataset, DatasetDict, concatenate_datasets\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load spaCy for POS tagging\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "selected_subset = \"test\"\n",
    "dataset = load_dataset(\"openai/gsm8k\", \"main\")[selected_subset]\n",
    "modified_dataset_name = \"GSM8k-NoOp-Plus\"\n",
    "\n",
    "hf_username = \"LFrancis\"\n",
    "repo_id = f\"{hf_username}/{modified_dataset_name}\"\n",
    "load_dotenv(\"../.env\")\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"VLLM_API_KEY\"),\n",
    "    base_url=\"http://134.76.18.30:8085/v1\"\n",
    ")\n",
    "model = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "df = pd.DataFrame(dataset)\n",
    "df"
   ],
   "id": "da48ae5c0f3b1307",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               question  \\\n",
       "0     Janet’s ducks lay 16 eggs per day. She eats th...   \n",
       "1     A robe takes 2 bolts of blue fiber and half th...   \n",
       "2     Josh decides to try flipping a house.  He buys...   \n",
       "3     James decides to run 3 sprints 3 times a week....   \n",
       "4     Every day, Wendi feeds each of her chickens th...   \n",
       "...                                                 ...   \n",
       "1314  John had a son James when he was 19.  James is...   \n",
       "1315  There are some oranges in a basket. Ana spends...   \n",
       "1316  Mark's car breaks down and he needs to get a n...   \n",
       "1317  Farmer Brown has 20 animals on his farm, all e...   \n",
       "1318  Henry and 3 of his friends order 7 pizzas for ...   \n",
       "\n",
       "                                                 answer  \n",
       "0     Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eg...  \n",
       "1     It takes 2/2=<<2/2=1>>1 bolt of white fiber\\nS...  \n",
       "2     The cost of the house and repairs came out to ...  \n",
       "3     He sprints 3*3=<<3*3=9>>9 times\\nSo he runs 9*...  \n",
       "4     If each chicken eats 3 cups of feed per day, t...  \n",
       "...                                                 ...  \n",
       "1314  Dora is 12-3=<<12-3=9>>9\\nSo James is 9*2=<<9*...  \n",
       "1315  There are 60 minutes in an hour. Ana peels an ...  \n",
       "1316  The discount on the radiator was 400*.8=$<<400...  \n",
       "1317  Let C be the number of chickens.\\nThere are 20...  \n",
       "1318  There are 7*8=<<7*8=56>>56 slices in total.\\nT...  \n",
       "\n",
       "[1319 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Janet’s ducks lay 16 eggs per day. She eats th...</td>\n",
       "      <td>Janet sells 16 - 3 - 4 = &lt;&lt;16-3-4=9&gt;&gt;9 duck eg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A robe takes 2 bolts of blue fiber and half th...</td>\n",
       "      <td>It takes 2/2=&lt;&lt;2/2=1&gt;&gt;1 bolt of white fiber\\nS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Josh decides to try flipping a house.  He buys...</td>\n",
       "      <td>The cost of the house and repairs came out to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>James decides to run 3 sprints 3 times a week....</td>\n",
       "      <td>He sprints 3*3=&lt;&lt;3*3=9&gt;&gt;9 times\\nSo he runs 9*...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Every day, Wendi feeds each of her chickens th...</td>\n",
       "      <td>If each chicken eats 3 cups of feed per day, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>John had a son James when he was 19.  James is...</td>\n",
       "      <td>Dora is 12-3=&lt;&lt;12-3=9&gt;&gt;9\\nSo James is 9*2=&lt;&lt;9*...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>There are some oranges in a basket. Ana spends...</td>\n",
       "      <td>There are 60 minutes in an hour. Ana peels an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>Mark's car breaks down and he needs to get a n...</td>\n",
       "      <td>The discount on the radiator was 400*.8=$&lt;&lt;400...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>Farmer Brown has 20 animals on his farm, all e...</td>\n",
       "      <td>Let C be the number of chickens.\\nThere are 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>Henry and 3 of his friends order 7 pizzas for ...</td>\n",
       "      <td>There are 7*8=&lt;&lt;7*8=56&gt;&gt;56 slices in total.\\nT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1319 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:32:55.078313Z",
     "start_time": "2025-01-06T12:32:55.043408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_dict = DatasetDict()\n",
    "dataset_dict[\"main\"] = Dataset.from_pandas(df)\n",
    "example_question = \"How can one differentiate a set and a dictionary in python?\"\n",
    "dataset_dict"
   ],
   "id": "7b4fe193ef4b75e5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    main: Dataset({\n",
       "        features: ['question', 'answer'],\n",
       "        num_rows: 1319\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:32:57.474321Z",
     "start_time": "2025-01-06T12:32:57.460770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def upload():\n",
    "    for subset in dataset_dict.keys():\n",
    "        print(\"Uploading\", subset)\n",
    "        dataset_dict[subset].push_to_hub(repo_id, subset)"
   ],
   "id": "8f7a1ffd1509f748",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "markdown",
   "source": "## Paraphrase Type: Naive Addition",
   "id": "e2d4da176f5705ba"
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-06T12:33:13.671418Z",
     "start_time": "2025-01-06T12:33:13.648291Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_sentence_to_question(question: str) -> str:\n",
    "    return question + \" \" + \"Sebastian goes to buy icecream.\"\n",
    "\n",
    "\n",
    "print(\"Rows mentioning 'Sebastian':\", len(df[df['question'].str.contains(\"Sebastian\")]))\n",
    "print(\"Rows mentioning 'icecream':\", len(df[df['question'].str.contains(\"icecream\")]))\n",
    "add_sentence_to_question(example_question)"
   ],
   "id": "5a6a869abf2d97c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows mentioning 'Sebastian': 0\n",
      "Rows mentioning 'icecream': 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'How can one differentiate a set and a dictionary in python? Sebastian goes to buy icecream.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:33:19.247026Z",
     "start_time": "2025-01-06T12:33:19.095918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_naive_sentence(row):\n",
    "    row[\"question\"] = add_sentence_to_question(row[\"question\"])\n",
    "    return row\n",
    "\n",
    "df_naive = pd.DataFrame(dataset_dict[\"main\"])\n",
    "df_naive = df_naive.progress_apply(add_naive_sentence, axis=1)\n",
    "dataset_naive = Dataset.from_pandas(df_naive)\n",
    "dataset_dict[\"main_naive\"] = dataset_naive\n",
    "pprint(list(dataset_dict.keys()))"
   ],
   "id": "2db48b93821d5294",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1319/1319 [00:00<00:00, 26182.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['main', 'main_naive']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:33:28.735794Z",
     "start_time": "2025-01-06T12:33:24.076338Z"
    }
   },
   "cell_type": "code",
   "source": "upload()",
   "id": "acc9a7a357a4e62f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading main\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b1a9399828244fcbb379b0cd799d4ae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a94bb9669a1b4300a08c22c67e862038"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading main_naive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b68d85601aec4242a2e1644f57d04815"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6fe527c91cd14c0ebe342d390c704dad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/327 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "119342cf636a44849f785179903a21bb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Paraphrase Type: Addition",
   "id": "6f70d4a9110a3bab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:39:30.811591Z",
     "start_time": "2025-01-06T12:39:27.993610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "preprompt = \"Give me one additional sentence to this question that has no direct effect on the question. The sentence should be about a similar topic. It should not be a question. Example additional sentences might focus on unnecessary details, add unnecessary information about other fields of study. Only output exactly the additional sentence and nothing else, the output will be copy/pasted as is. It is extremely important that the sentence does not effect the answer to the question.\"\n",
    "\n",
    "addition_prompt = lambda question: str(preprompt + f\"\\nQuestion: \\n'{question}'\\nAdditional sentence:\")\n",
    "\n",
    "def add_additional_information(narrative: str) -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": addition_prompt(narrative),\n",
    "            }\n",
    "        ],\n",
    "        model=model,\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    return narrative + \" \" + result\n",
    "\n",
    "add_additional_information(example_question)"
   ],
   "id": "280023f311f0c678",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How can one differentiate a set and a dictionary in python? In computer science, the concept of data structures is closely related to theoretical computer science, which studies the fundamental properties and behaviors of computation itself.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:56:54.713249Z",
     "start_time": "2025-01-06T12:48:58.874671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_additional_sentence(row):\n",
    "    row[\"question\"] = add_additional_information(row[\"question\"])\n",
    "    return row\n",
    "\n",
    "\n",
    "df_additional = pd.DataFrame(dataset_dict[\"main\"])\n",
    "df_additional = df_additional.progress_apply(add_additional_sentence, axis=1)\n",
    "dataset_additional = Dataset.from_pandas(df_additional)\n",
    "dataset_dict[\"main_addition\"] = dataset_additional\n",
    "pprint(list(dataset_dict.keys()))"
   ],
   "id": "153c4cdf0b316da4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1319/1319 [07:55<00:00,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['main', 'main_naive', 'main_addition']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:57:02.199128Z",
     "start_time": "2025-01-06T12:56:57.657364Z"
    }
   },
   "cell_type": "code",
   "source": "upload()",
   "id": "bca5666b17c6e3f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading main\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8ac07f5043684a32ae3591fcd7022191"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d0d3193fa7b843a2a318643616769457"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/641 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2d06b3ea550841c2b9a7b98989e856bb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading main_naive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eaa48b5df14842cfb47b4e4991368d65"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0a7954fd2bc04a29a0cdbc3c1f5dedd7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading main_addition\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "012722f8c30e49bd8318ae92967746f0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9338c36b1c664d838de095b06124b106"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Paraphrase Type: Lexicon-Changes\n",
   "id": "3af5f01884e9f923"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T12:57:16.844818Z",
     "start_time": "2025-01-06T12:57:15.653931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def fetch_alternative(blanked, original_word):\n",
    "    prompt = f\"Output exactly one word that fits where the placeholder '<BLANK>' is placed and has similar meaning to '{original_word}'. No other output besides the word.\\nText: '{''.join(blanked)}'\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        max_tokens=5,\n",
    "        top_logprobs=5,\n",
    "        logprobs=True,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    choice = response.choices[0]\n",
    "    if choice.logprobs.content[0].logprob >= -1:\n",
    "        return choice.message.content.lower().strip().replace(\".\", \"\")\n",
    "    return original_word\n",
    "\n",
    "\n",
    "def paraphrase_with_second_best_threading(text):\n",
    "    doc = nlp(text)\n",
    "    words = [token.text_with_ws for token in doc]\n",
    "    pos_tags = [token.pos_ for token in doc]\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = []\n",
    "        for i, pos in enumerate(pos_tags):\n",
    "            if pos == \"ADJ\":\n",
    "                blanked = words.copy()\n",
    "                blanked[i] = \"<BLANK>\"\n",
    "                future = executor.submit(fetch_alternative, blanked, words[i])\n",
    "                futures.append((i, future))\n",
    "\n",
    "        for i, future in futures:\n",
    "            alt = future.result()\n",
    "            if alt != words[i]:\n",
    "                words[i] = alt + doc[i].whitespace_\n",
    "\n",
    "    return \"\".join(words)\n",
    "\n",
    "\n",
    "story = \"Once upon a time, there was a brave knight who fought dragons.\"\n",
    "\n",
    "# Get the paraphrased story\n",
    "paraphrased_story = paraphrase_with_second_best_threading(story)\n",
    "print(\"Original Story:\", story)\n",
    "print(\"Paraphrased Story:\", paraphrased_story)\n"
   ],
   "id": "2084900e4d7c12c3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Story: Once upon a time, there was a brave knight who fought dragons.\n",
      "Paraphrased Story: Once upon a time, there was a hero knight who fought dragons.\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T13:00:31.984837Z",
     "start_time": "2025-01-06T12:57:21.903049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def paraphrase_single_words(row):\n",
    "    row[\"question\"] = paraphrase_with_second_best_threading(row[\"question\"])\n",
    "    return row\n",
    "\n",
    "\n",
    "df_lex = pd.DataFrame(dataset_dict[\"main\"])\n",
    "df_lex = df_lex.progress_apply(paraphrase_single_words, axis=1)\n",
    "dataset_lex = Dataset.from_pandas(df_lex)\n",
    "dataset_dict[\"main_lexicon\"] = dataset_lex\n",
    "\n",
    "dataset_dict.keys()"
   ],
   "id": "d0b5d00a4ba54e62",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1319/1319 [03:10<00:00,  6.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['main', 'main_naive', 'main_addition', 'main_lexicon'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T13:00:44.990096Z",
     "start_time": "2025-01-06T13:00:38.565434Z"
    }
   },
   "cell_type": "code",
   "source": "upload()",
   "id": "e4844f39cdde23bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading main\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d16af423a92944d99592bd50746fa1fc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3bac0171624241d9a99e1791d21bf4c4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23d0dee3df714f3c95a598049da7a620"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading main_naive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3574ff0c4d754f7ca993408037d3cdca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33fa2e0f987d4f11bd386c162bc7fed9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading main_addition\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72f1c99710cb4052afec8d41de874810"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4880e1401fa9434fa1725e4ce98b45e5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading main_lexicon\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "348911214813458eb662294206ca1f7a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4c78f4600c494564a6b25156f21f7d4b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Paraphrase Type: Syntax-Changes\n",
   "id": "9311a162e96e675"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T13:00:50.981282Z",
     "start_time": "2025-01-06T13:00:50.957467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def rephrase_sentence(sentence):\n",
    "    # Parse the sentence\n",
    "    doc = nlp(sentence)\n",
    "    proper_nouns = {token.text.lower() for token in doc if token.pos_ == \"PROPN\" or token.ent_type_}\n",
    "\n",
    "    # Example: Moving adverbs to the beginning\n",
    "    words = []\n",
    "    adverbs = []\n",
    "\n",
    "    # Split ADV from sentence\n",
    "    for token in doc:\n",
    "        word = token.text_with_ws.capitalize() if token.text.lower() in proper_nouns else token.text_with_ws.lower()\n",
    "        if token.pos_ == \"ADV\":  # Identify adverbs\n",
    "            adverbs.append(word)\n",
    "        else:\n",
    "            words.append(word)\n",
    "\n",
    "    reordered = \"\".join(adverbs + words)\n",
    "    # Capitalize the first word of the sentence\n",
    "    if reordered:\n",
    "        reordered = reordered[0].upper() + reordered[1:]\n",
    "\n",
    "    return reordered\n",
    "\n",
    "# Test the function\n",
    "sentence = \"Alice quickly ran to the store in New York.\"\n",
    "rephrased = rephrase_sentence(sentence)\n",
    "print(\"Original:\", sentence)\n",
    "print(\"Rephrased:\", rephrased)"
   ],
   "id": "ca7fd34807441668",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Alice quickly ran to the store in New York.\n",
      "Rephrased: Quickly Alice ran to the store in New York.\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T13:00:54.969959Z",
     "start_time": "2025-01-06T13:00:54.944256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example paragraph\n",
    "paragraph = \"\"\"Because it was raining, she stayed indoors. The weather had been unpredictable all week.\n",
    "She decided to read a book, hoping the rain would stop. By evening, the sun came out.\n",
    "\"\"\"\n",
    "\n",
    "def split_paragraph_into_sentences(paragraph):\n",
    "    doc = nlp(paragraph)\n",
    "    sentences = [sent.text for sent in doc.sents]\n",
    "    return sentences\n",
    "\n",
    "# Split paragraph into sentences\n",
    "sentences = split_paragraph_into_sentences(paragraph)\n",
    "\n",
    "# Print the sentences\n",
    "for sentence in sentences:\n",
    "    print(\"#\",sentence)\n"
   ],
   "id": "3f1999fd1f5a43c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Because it was raining, she stayed indoors.\n",
      "# The weather had been unpredictable all week.\n",
      "\n",
      "# She decided to read a book, hoping the rain would stop.\n",
      "# By evening, the sun came out.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T13:01:25.886906Z",
     "start_time": "2025-01-06T13:01:10.129307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def rephrase_narrative(row):\n",
    "    row[\"question\"] = \"\".join([rephrase_sentence(sentence) for sentence in split_paragraph_into_sentences(row[\"question\"])])\n",
    "    return row\n",
    "\n",
    "\n",
    "df_syn = pd.DataFrame(dataset_dict[\"main\"])\n",
    "df_syn = df_syn.progress_apply(rephrase_narrative, axis=1)\n",
    "dataset_syn = Dataset.from_pandas(df_syn)\n",
    "dataset_dict[\"main_syntax\"] = dataset_syn\n",
    "\n",
    "dataset_dict.keys()"
   ],
   "id": "5d1018e2aa2bb754",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1319/1319 [00:15<00:00, 84.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['main', 'main_naive', 'main_addition', 'main_lexicon', 'main_syntax'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T13:03:58.320890Z",
     "start_time": "2025-01-06T13:03:58.309674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pprint(dataset_dict[(\"main\")][0][\"question\"])\n",
    "pprint(dataset_dict[(\"main_syntax\")][0][\"question\"])"
   ],
   "id": "f05ffdfeaa827720",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Janet’s ducks lay 16 eggs per day. She eats three for breakfast every '\n",
      " 'morning and bakes muffins for her friends every day with four. She sells the '\n",
      " \"remainder at the farmers' market daily for $2 per fresh duck egg. How much \"\n",
      " \"in dollars does she make every day at the farmers' market?\")\n",
      "('Janet’s ducks lay 16 eggs per day.She eats Three for breakfast Every Morning '\n",
      " 'and bakes muffins for her friends Every day with Four.Daily she sells the '\n",
      " \"remainder at the farmers' market for $2 per fresh duck egg.How much in \"\n",
      " \"dollars does she make every day at the farmers' market?\")\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T13:01:35.646950Z",
     "start_time": "2025-01-06T13:01:28.739373Z"
    }
   },
   "cell_type": "code",
   "source": "upload()",
   "id": "4f75e9dd4f309d4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading main\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "69708106ed594edc87ad8b9cae81fca3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c455767f283442ca66deee24cb2c8bb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/1.28k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "90e890b3874941f5b366b5db155cf741"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading main_naive\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1777d480c4ad416a86795243699ea381"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "53de020cd00849cba89722e99108e4cd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading main_addition\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6b1169e905ab4b5db01ec481d8fa13a6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "59ce28f3d2d84714a43337b248a150f4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading main_lexicon\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f4b486704f514fcc804adf6cb3f5ab88"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "954d2bcccd2549b9ae09194e140c690d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading main_syntax\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aeebf2fa5ee548d79043cdfe691fa374"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "40f2e0e20edc4465ba0888bb41ebfc0d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Paraphrase Type: Deletion\n",
   "id": "168dbd9284660175"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "not applicable",
   "id": "4058c6115a9d54b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "128d915ab35d2532",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
