{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T12:33:13.841884Z",
     "start_time": "2025-01-08T12:33:11.274858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os.path\n",
    "\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from dotenv import load_dotenv\n",
    "from typing_extensions import override\n",
    "\n",
    "load_dotenv(\"../.env\")\n",
    "# Load GSM8k Dataset\n",
    "dataset_name = \"LFrancis/GSM8k-NoOp-Plus\"\n",
    "baseline_dataset_name = \"openai/gsm8k\"\n",
    "subset = \"main_lexicon\"\n",
    "dataset = load_dataset(dataset_name, subset)[\"train\"]\n",
    "\n",
    "# VLLM API Configuration\n",
    "BASE_URL = \"http://134.76.18.30:8085/v1/chat/completions\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\", \"Authorization\": \"Bearer \"+os.getenv(\"VLLM_API_KEY\")}\n",
    "MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "EVALUATED_MODEL_PATH = dataset_name+\"_\"+subset + \"_evaluated_\" + MODEL_NAME\n",
    "BASELINE_MODEL_PATH = baseline_dataset_name + \"_evaluated_\" + MODEL_NAME\n",
    "if not os.path.exists(EVALUATED_MODEL_PATH):\n",
    "    dataset.save_to_disk(EVALUATED_MODEL_PATH)\n",
    "if not os.path.exists(BASELINE_MODEL_PATH):\n",
    "    baseline_dataset = load_dataset(baseline_dataset_name, subset)[\"test\"]\n",
    "    baseline_dataset.save_to_disk(BASELINE_MODEL_PATH)"
   ],
   "id": "62b73412d8b897a7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/420k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c259277081e6474d993cdd412df0bd6f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/1319 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4e053dc4719f4be4b980920b0d94d10b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1319 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ba8e35a62e5444c9c1a7867696b036d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T12:33:13.857808Z",
     "start_time": "2025-01-08T12:33:13.850380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import Dataset\n",
    "import requests\n",
    "\n",
    "\n",
    "# Helper Functions\n",
    "def create_chat_messages(question, sys_msg):\n",
    "    \"\"\"\n",
    "    Create a formatted list of chat messages for the chat model.\n",
    "    \"\"\"\n",
    "    user_prompt = f\"{question}\\n\" + \"\\nCalculations:\"\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": sys_msg},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "\n",
    "def query_vllm_api(payload):\n",
    "    \"\"\"\n",
    "    Send a query to the VLLM API and return the response.\n",
    "    \"\"\"\n",
    "    response = requests.post(BASE_URL, json=payload, headers=HEADERS, timeout=120)\n",
    "    response.raise_for_status()  # Raise an error for HTTP issues\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def evaluate_question(entry):\n",
    "    # Step 1: Generate reasoning (CoT) response\n",
    "    sys_msg = \"The following are gradeschool math questions. Think step by step and answer with a single number when prompted for a final answer. The final answer cannot include anything other than a single number, please do not include any additional calculations, clarifications or units.\\nRemember: Always answer in the format '#### [number]'.\"\n",
    "    question = entry[\"question\"]\n",
    "    messages = create_chat_messages(question, sys_msg)\n",
    "\n",
    "    cot_payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 200,\n",
    "        \"temperature\": 0.0,\n",
    "    }\n",
    "\n",
    "    cot_response = query_vllm_api(cot_payload)\n",
    "    if \"object\" in cot_response.keys() and cot_response[\"object\"] == \"error\":\n",
    "        raise Exception(cot_response[\"message\"])\n",
    "\n",
    "    cot_text = cot_response[\"choices\"][0][\"message\"][\"content\"].strip()  # Extract CoT reasoning\n",
    "\n",
    "    # Step 2: Calculate logprobs for each choice\n",
    "    final_prompt = \"(Answer with a single number, starting after ####. Do not include anything other than #### followed by the number.) Final Answer: \"\n",
    "    choice_messages = [\n",
    "        *messages,\n",
    "        {\"role\": \"system\", \"content\": cot_text},\n",
    "        {\"role\": \"user\", \"content\": final_prompt}\n",
    "    ]\n",
    "    final_payload = {\n",
    "            \"model\": MODEL_NAME,\n",
    "            \"messages\": choice_messages,\n",
    "            \"max_tokens\": 10,\n",
    "            \"temperature\": 0.0,\n",
    "            \"stop\": [\"\\n\"],\n",
    "        }\n",
    "    final_response = query_vllm_api(final_payload)\n",
    "    gen_answer = final_response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    gen_answer = extract_answer(gen_answer)\n",
    "    entry[\"generated_answer\"] = gen_answer\n",
    "    entry[\"generated_cot\"] = cot_text\n",
    "    return entry\n",
    "\n",
    "\n",
    "def extract_answer(gen_answer):\n",
    "    answer = gen_answer.split(\"#### \")\n",
    "    if len(answer) != 2:\n",
    "        if answer[0].strip().isnumeric():\n",
    "            # Recover answer even though answer is formatted wrong\n",
    "            return answer[0].strip()\n",
    "        raise Exception(f\"{gen_answer} is not a valid answer.\")\n",
    "    return answer[1].strip()\n",
    "\n",
    "\n",
    "def is_correct(entry):\n",
    "    \"\"\"\n",
    "    Determines if the choice with the lowest log probability corresponds to the correct answer.\n",
    "\n",
    "    Args:\n",
    "        entry (dict): A dictionary containing the question, choices, answer index, and logprobs.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the option with the lowest logprob matches the correct answer index, False otherwise.\n",
    "    \"\"\"\n",
    "    # Extract logprobs and the correct answer index\n",
    "    gen_answer = entry['generated_answer']\n",
    "    if gen_answer is None:\n",
    "        return False\n",
    "    answer = extract_answer(entry['answer'])\n",
    "\n",
    "    return answer == gen_answer\n",
    "\n",
    "\n",
    "def process_dataset(dataset: Dataset, numproc=1):\n",
    "    \"\"\"\n",
    "    Process the dataset using Dataset.map.\n",
    "    \"\"\"\n",
    "\n",
    "    def process_entry(entry):\n",
    "        if \"generated_answer\" in entry.keys() and entry[\"generated_answer\"] is not None:\n",
    "            return entry\n",
    "        try:\n",
    "            return evaluate_question(entry)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing entry: {entry}, Exception: {e}\")\n",
    "            entry[\"generated_answer\"] = None\n",
    "            entry[\"generated_cot\"] = None\n",
    "            return entry\n",
    "    return dataset.map(process_entry, with_indices=False, num_proc=numproc)"
   ],
   "id": "c60fc0802c475748",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T12:33:13.867725Z",
     "start_time": "2025-01-08T12:33:13.865368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def update_dataset(dataset, is_baseline = False):\n",
    "    # Save the updated dataset to a temporary location\n",
    "    temp_path = \"temp\"\n",
    "    dataset.save_to_disk(temp_path)\n",
    "\n",
    "    # Overwrite the original dataset directory\n",
    "    import shutil\n",
    "    original_path = EVALUATED_MODEL_PATH if is_baseline == False else BASELINE_MODEL_PATH\n",
    "\n",
    "    # Remove the old dataset and replace it with the new one\n",
    "    shutil.rmtree(original_path)  # Remove the old dataset directory\n",
    "    shutil.move(temp_path, original_path)"
   ],
   "id": "e0ee2b6c396f28dd",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T12:34:44.478086Z",
     "start_time": "2025-01-08T12:34:38.075882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main(is_continue = False, is_baseline=False, numproc=1):\n",
    "    \"\"\"\n",
    "    Main function to evaluate the dataset asynchronously.\n",
    "    \"\"\"\n",
    "    if is_baseline:\n",
    "        selected_dataset = load_from_disk(BASELINE_MODEL_PATH)\n",
    "    elif is_continue:\n",
    "        selected_dataset = load_from_disk(EVALUATED_MODEL_PATH)\n",
    "    else:\n",
    "        selected_dataset = dataset\n",
    "    # Process the dataset asynchronously\n",
    "    processed_dataset = process_dataset(selected_dataset, numproc)\n",
    "\n",
    "    # Save the updated dataset\n",
    "    update_dataset(processed_dataset, is_baseline)\n",
    "# Run the script\n",
    "main(True, False, 1)"
   ],
   "id": "6c05b4e127512852",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1319 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be878cf6762f455588a0a14a8e684642"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing entry: {'question': 'Nick is choosing between two jobs. Job A pays $15 an hour for 2000 hours a year, and is in a state with a 20% total tax rate. Job B pays $42,000 a year and is in a state that charges $6,000 in property tax and a 10% tax rate on net income after property tax. How much extra money will Nick make at the job with a higher takehome pay rate, compared to the other job?', 'answer': \"First calculate the gross annual salary for Job A: 2000 hours * $15/hour = $<<2000*15=30000>>30,000\\nNext, calculate the amount of taxes Nick pays at Job A by multiplying his net salary by the 20% tax rate: .2 * $30,000 = $<<30000*.2=6000>>6,000\\nNow subtract Nick's taxes from his net pay to find his gross pay at Job A: $30,000 - $6,000 = $<<30000-6000=24000>>24,000\\nNow subtract Nick's property taxes from his gross income at Job B: $42,000 - $6,000 = $<<42000-6000=36000>>36,000\\nNow multiply Nick's income after property tax by 10% to find his income tax at Job B: $36,000 * 10% = $<<36000*10*.01=3600>>3,600\\nNow subtract the income tax amount from Nick's earnings after property tax to find his net income at Job B: $36,000 - $3,600 = $<<36000-3600=32400>>32,400\\nNow subtract the net income from the lower-paying job (A) from the net income from the higher-paying job (B): $32,400 - $24,000 = $<<32400-24000=8400>>8,400\\n#### 8400\", 'generated_answer': None, 'generated_cot': None}, Exception: Taxes for Job B = 0.10 is not a valid answer.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1319 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7b568b5331814e0584c51eac75817f30"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T12:34:49.599886Z",
     "start_time": "2025-01-08T12:34:49.555024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save or process results as needed\n",
    "selected_dataset = load_from_disk(EVALUATED_MODEL_PATH)\n",
    "score = [is_correct(result) for result in selected_dataset]\n",
    "score = sum(score) / len(score)\n",
    "print(\"Accuracy\", score)"
   ],
   "id": "d6511a8a3f86cbc0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7035633055344959\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T12:34:52.192893Z",
     "start_time": "2025-01-08T12:34:52.158113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "baseline_dataset = load_from_disk(BASELINE_MODEL_PATH)\n",
    "score = [is_correct(result) for result in baseline_dataset]\n",
    "score = sum(score) / len(score)\n",
    "print(\"Baseline Accuracy\", score)"
   ],
   "id": "57d06cdc2ef4c6ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy 0.7816527672479151\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T15:50:50.749983Z",
     "start_time": "2025-01-06T15:50:50.728282Z"
    }
   },
   "cell_type": "code",
   "source": "selected_dataset[0][\"question\"]",
   "id": "47d01683370245ab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market? Janet's love for environmental conservation is also evident in her extensive collection of exotic bird species in her backyard.\""
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-06T15:51:07.928482Z",
     "start_time": "2025-01-06T15:51:07.916314Z"
    }
   },
   "cell_type": "code",
   "source": "baseline_dataset[0][\"question\"]",
   "id": "87ece965233f60a2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\""
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "425570df70200025"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
