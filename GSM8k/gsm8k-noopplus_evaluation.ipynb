{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:41:50.812888Z",
     "start_time": "2025-03-12T08:41:50.794977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "1a91ab279ab049e2",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:41:53.339025Z",
     "start_time": "2025-03-12T08:41:50.816364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os.path\n",
    "\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\")\n",
    "# Load GSM8k Dataset\n",
    "dataset_name = \"LFrancis/GSM8k-NoOp-Plus\"\n",
    "baseline_dataset_name = \"openai/gsm8k\"\n",
    "subset = \"main_typo_add_random\"\n",
    "dataset = load_dataset(dataset_name, subset)[\"train\"]\n",
    "\n",
    "# VLLM API Configuration\n",
    "BASE_URL = \"http://134.76.18.30:8081/v1/chat/completions\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\", \"Authorization\": \"Bearer \" + os.getenv(\"VLLM_API_KEY\")}\n",
    "MODEL_NAME = \"meta-llama/Llama-3.3-70B-Instruct\"\n",
    "\n",
    "EVALUATED_MODEL_PATH = dataset_name + \"_\" + subset + \"_evaluated_\" + MODEL_NAME\n",
    "BASELINE_MODEL_PATH = baseline_dataset_name + \"_evaluated_\" + MODEL_NAME\n",
    "\n",
    "if not os.path.exists(EVALUATED_MODEL_PATH):\n",
    "    dataset.save_to_disk(EVALUATED_MODEL_PATH)\n",
    "if not os.path.exists(BASELINE_MODEL_PATH):\n",
    "    baseline_dataset = load_dataset(baseline_dataset_name, subset)[\"test\"]\n",
    "    baseline_dataset.save_to_disk(BASELINE_MODEL_PATH)"
   ],
   "id": "62b73412d8b897a7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1319 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "62c24947dec04a688f393b0046bd60ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:41:53.361905Z",
     "start_time": "2025-03-12T08:41:53.345431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "from datasets import Dataset\n",
    "import requests\n",
    "\n",
    "\n",
    "# Helper Functions\n",
    "def create_chat_messages(question, sys_msg):\n",
    "    \"\"\"\n",
    "    Create a formatted list of chat messages for the chat model.\n",
    "    \"\"\"\n",
    "    user_prompt = f\"{question}\\n\" + \"\\nCalculations:\"\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": sys_msg},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "\n",
    "def query_vllm_api(payload):\n",
    "    \"\"\"\n",
    "    Send a query to the VLLM API and return the response.\n",
    "    \"\"\"\n",
    "    response = requests.post(BASE_URL, json=payload, headers=HEADERS, timeout=120)\n",
    "    response.raise_for_status()  # Raise an error for HTTP issues\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def evaluate_question(entry):\n",
    "    # Step 1: Generate reasoning (CoT) response\n",
    "    sys_msg = \"The following are math questions. Think step by step. State your final answer at the end of your calculations.\"\n",
    "    question = entry[\"question\"]\n",
    "    messages = create_chat_messages(question, sys_msg)\n",
    "\n",
    "    cot_payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 2000,\n",
    "        \"temperature\": 0.0,\n",
    "    }\n",
    "\n",
    "    cot_response = query_vllm_api(cot_payload)\n",
    "    if \"object\" in cot_response.keys() and cot_response[\"object\"] == \"error\":\n",
    "        raise Exception(cot_response[\"message\"])\n",
    "\n",
    "    cot_text = cot_response[\"choices\"][0][\"message\"][\"content\"].strip()  # Extract CoT reasoning\n",
    "    gen_answer = extract_answer(cot_text)\n",
    "    entry[\"generated_answer\"] = gen_answer\n",
    "    entry[\"generated_cot\"] = cot_text\n",
    "    return entry\n",
    "\n",
    "\n",
    "def extract_answer(gen_answer):\n",
    "    # Remove commas so for example 5,000 becomes 5000\n",
    "    model_resp = gen_answer.replace(\",\", \"\")\n",
    "    # Find the last number\n",
    "    extracted_num = re.findall(r\"-?\\d+\\.?\\d*\", model_resp)[-1]\n",
    "    # Use float to ensure 3.0 and 3 are the same.\n",
    "    return str(float(extracted_num))\n",
    "\n",
    "\n",
    "def is_correct(entry):\n",
    "    \"\"\"\n",
    "    Determines if the choice with the lowest log probability corresponds to the correct answer.\n",
    "\n",
    "    Args:\n",
    "        entry (dict): A dictionary containing the question, choices, answer index, and logprobs.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the option with the lowest logprob matches the correct answer index, False otherwise.\n",
    "    \"\"\"\n",
    "    # Extract logprobs and the correct answer index\n",
    "    gen_answer = entry['generated_answer']\n",
    "    if gen_answer == \"\":\n",
    "        return False\n",
    "    answer = extract_answer(entry['answer'])\n",
    "\n",
    "    return answer == gen_answer\n",
    "\n",
    "\n",
    "def process_dataset(dataset: Dataset, numproc=1):\n",
    "    \"\"\"\n",
    "    Process the dataset using Dataset.map.\n",
    "    \"\"\"\n",
    "\n",
    "    def process_entry(entry):\n",
    "        if \"generated_answer\" in entry.keys() and not entry[\"generated_answer\"] == \"\":\n",
    "            return entry\n",
    "        try:\n",
    "            return evaluate_question(entry)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing entry: {entry}, Exception: {e}\")\n",
    "            entry[\"generated_answer\"] = \"\"\n",
    "            entry[\"generated_cot\"] = \"\"\n",
    "            return entry\n",
    "\n",
    "    return dataset.map(process_entry, with_indices=False, num_proc=numproc)"
   ],
   "id": "c60fc0802c475748",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:41:53.377331Z",
     "start_time": "2025-03-12T08:41:53.366326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def update_dataset(dataset, is_baseline=False):\n",
    "    # Save the updated dataset to a temporary location\n",
    "    temp_path = \"temp\"\n",
    "    dataset.save_to_disk(temp_path)\n",
    "\n",
    "    # Overwrite the original dataset directory\n",
    "    import shutil\n",
    "    original_path = EVALUATED_MODEL_PATH if is_baseline == False else BASELINE_MODEL_PATH\n",
    "\n",
    "    # Remove the old dataset and replace it with the new one\n",
    "    shutil.rmtree(original_path)  # Remove the old dataset directory\n",
    "    shutil.move(temp_path, original_path)"
   ],
   "id": "e0ee2b6c396f28dd",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:47:15.165804Z",
     "start_time": "2025-03-12T08:43:55.781671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main(is_continue=False, is_baseline=False, numproc=1):\n",
    "    \"\"\"\n",
    "    Main function to evaluate the dataset asynchronously.\n",
    "    \"\"\"\n",
    "    if is_baseline:\n",
    "        selected_dataset = load_from_disk(BASELINE_MODEL_PATH)\n",
    "    elif is_continue:\n",
    "        selected_dataset = load_from_disk(EVALUATED_MODEL_PATH)\n",
    "    else:\n",
    "        selected_dataset = dataset\n",
    "    # Process the dataset asynchronously\n",
    "    processed_dataset = process_dataset(selected_dataset, numproc)\n",
    "\n",
    "    # Save the updated dataset\n",
    "    update_dataset(processed_dataset, is_baseline)\n",
    "\n",
    "\n",
    "# Run the script\n",
    "main(True, False, 75)"
   ],
   "id": "6c05b4e127512852",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map (num_proc=75):   0%|          | 0/1319 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b61aacbff28a494db5af703b9f93ffef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1319 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "16796462cb3245b09c76abf3a5bda9c2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:47:15.447784Z",
     "start_time": "2025-03-12T08:47:15.172685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from converter.converter import save_value_to_json\n",
    "\n",
    "for ss in [\"addition\", \"lexicon\", \"syntax\", \"scramble\", \"naive\", \"typo_qwerty\", 'typo_doubling',\n",
    "    'typo_deletion',\n",
    "    'typo_hold_down',\n",
    "    'typo_add_random', \"our_baseline\", \"\", \"typo\"]:\n",
    "    if ss == \"\":\n",
    "        model_path = dataset_name + \"_main\" + \"_evaluated_\" + MODEL_NAME\n",
    "        ss = \"our_baseline\"\n",
    "    else:\n",
    "        model_path = dataset_name + \"_main_\" + ss + \"_evaluated_\" + MODEL_NAME\n",
    "    if os.path.exists(model_path):\n",
    "        selected_dataset = load_from_disk(model_path)\n",
    "        print(model_path)\n",
    "        print(selected_dataset)\n",
    "        score = [is_correct(result) for result in selected_dataset]\n",
    "        score = sum(score) / len(score)\n",
    "        save_value_to_json(ss, score, MODEL_NAME)\n",
    "        print(ss, \"accuracy\", score)\n",
    "    else:\n",
    "        print(\"skipping\", model_path)"
   ],
   "id": "d6511a8a3f86cbc0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LFrancis/GSM8k-NoOp-Plus_main_addition_evaluated_meta-llama/Llama-3.3-70B-Instruct\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'generated_answer', 'generated_cot'],\n",
      "    num_rows: 1319\n",
      "})\n",
      "addition accuracy 0.9211523881728583\n",
      "LFrancis/GSM8k-NoOp-Plus_main_lexicon_evaluated_meta-llama/Llama-3.3-70B-Instruct\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'generated_answer', 'generated_cot'],\n",
      "    num_rows: 1319\n",
      "})\n",
      "lexicon accuracy 0.8218347232752085\n",
      "LFrancis/GSM8k-NoOp-Plus_main_syntax_evaluated_meta-llama/Llama-3.3-70B-Instruct\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'generated_answer', 'generated_cot'],\n",
      "    num_rows: 1319\n",
      "})\n",
      "syntax accuracy 0.9264594389689158\n",
      "LFrancis/GSM8k-NoOp-Plus_main_scramble_evaluated_meta-llama/Llama-3.3-70B-Instruct\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'generated_answer', 'generated_cot'],\n",
      "    num_rows: 1319\n",
      "})\n",
      "scramble accuracy 0.8908263836239575\n",
      "LFrancis/GSM8k-NoOp-Plus_main_naive_evaluated_meta-llama/Llama-3.3-70B-Instruct\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'generated_answer', 'generated_cot'],\n",
      "    num_rows: 1319\n",
      "})\n",
      "naive accuracy 0.9583017437452616\n",
      "LFrancis/GSM8k-NoOp-Plus_main_typo_qwerty_evaluated_meta-llama/Llama-3.3-70B-Instruct\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'generated_answer', 'generated_cot'],\n",
      "    num_rows: 1319\n",
      "})\n",
      "typo_qwerty accuracy 0.7975739196360879\n",
      "LFrancis/GSM8k-NoOp-Plus_main_typo_doubling_evaluated_meta-llama/Llama-3.3-70B-Instruct\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'generated_answer', 'generated_cot'],\n",
      "    num_rows: 1319\n",
      "})\n",
      "typo_doubling accuracy 0.6277482941622441\n",
      "LFrancis/GSM8k-NoOp-Plus_main_typo_deletion_evaluated_meta-llama/Llama-3.3-70B-Instruct\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'generated_answer', 'generated_cot'],\n",
      "    num_rows: 1319\n",
      "})\n",
      "typo_deletion accuracy 0.5481425322213799\n",
      "LFrancis/GSM8k-NoOp-Plus_main_typo_hold_down_evaluated_meta-llama/Llama-3.3-70B-Instruct\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'generated_answer', 'generated_cot'],\n",
      "    num_rows: 1319\n",
      "})\n",
      "typo_hold_down accuracy 0.6254738438210766\n",
      "LFrancis/GSM8k-NoOp-Plus_main_typo_add_random_evaluated_meta-llama/Llama-3.3-70B-Instruct\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'generated_answer', 'generated_cot'],\n",
      "    num_rows: 1319\n",
      "})\n",
      "typo_add_random accuracy 0.8733889310083397\n",
      "skipping LFrancis/GSM8k-NoOp-Plus_main_our_baseline_evaluated_meta-llama/Llama-3.3-70B-Instruct\n",
      "LFrancis/GSM8k-NoOp-Plus_main_evaluated_meta-llama/Llama-3.3-70B-Instruct\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'generated_answer', 'generated_cot'],\n",
      "    num_rows: 1319\n",
      "})\n",
      "our_baseline accuracy 0.9583017437452616\n",
      "LFrancis/GSM8k-NoOp-Plus_main_typo_evaluated_meta-llama/Llama-3.3-70B-Instruct\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'generated_answer', 'generated_cot'],\n",
      "    num_rows: 1319\n",
      "})\n",
      "typo accuracy 0.9150871872630781\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:41:53.880458Z",
     "start_time": "2025-03-10T16:36:22.113878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "baseline_dataset = load_from_disk(BASELINE_MODEL_PATH)\n",
    "score = [is_correct(result) for result in baseline_dataset]\n",
    "score = sum(score) / len(score)\n",
    "save_value_to_json(\"baseline\", score, MODEL_NAME)\n",
    "print(\"Baseline Accuracy\", score)"
   ],
   "id": "57d06cdc2ef4c6ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy 0.9575435936315391\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:41:53.881244Z",
     "start_time": "2025-03-10T16:36:22.156883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "selected_dataset = load_from_disk(dataset_name + \"_main_addition_evaluated_\" + MODEL_NAME)\n",
    "selected_dataset[0][\"generated_cot\"]"
   ],
   "id": "47d01683370245ab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To find out how much Janet makes every day at the farmers' market, we first need to determine how many eggs she sells. \\n\\n1. Janet's ducks lay 16 eggs per day.\\n2. She eats 3 eggs for breakfast.\\n3. She uses 4 eggs to bake muffins.\\n\\nTotal eggs used = 3 (for breakfast) + 4 (for muffins) = 7 eggs\\n\\n4. To find the number of eggs she sells, subtract the total eggs used from the total eggs laid:\\n   Eggs sold = Total eggs laid - Total eggs used\\n             = 16 - 7\\n             = 9 eggs\\n\\n5. Since she sells each egg for $2, her daily earnings from the farmers' market can be calculated as follows:\\n   Daily earnings = Number of eggs sold * Price per egg\\n                  = 9 * $2\\n                  = $18\\n\\nFinal answer: $18\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:41:53.881436Z",
     "start_time": "2025-03-10T16:36:22.177898Z"
    }
   },
   "cell_type": "code",
   "source": "baseline_dataset[0][\"question\"]",
   "id": "87ece965233f60a2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Janetâ€™s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T08:41:53.884384Z",
     "start_time": "2025-03-10T16:36:22.198540Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "425570df70200025",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
