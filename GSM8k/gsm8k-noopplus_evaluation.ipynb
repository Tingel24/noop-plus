{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T10:02:53.493055Z",
     "start_time": "2025-01-23T10:02:53.477591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "1a91ab279ab049e2",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T10:11:39.762587Z",
     "start_time": "2025-01-23T10:11:38.288700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os.path\n",
    "\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\")\n",
    "# Load GSM8k Dataset\n",
    "dataset_name = \"LFrancis/GSM8k-NoOp-Plus\"\n",
    "baseline_dataset_name = \"openai/gsm8k\"\n",
    "subset = \"main_scramble\"\n",
    "dataset = load_dataset(dataset_name, subset)[\"train\"]\n",
    "\n",
    "# VLLM API Configuration\n",
    "BASE_URL = \"http://134.76.18.30:8082/v1/chat/completions\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\", \"Authorization\": \"Bearer \" + os.getenv(\"VLLM_API_KEY\")}\n",
    "MODEL_NAME = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "EVALUATED_MODEL_PATH = dataset_name + \"_\" + subset + \"_evaluated_\" + MODEL_NAME\n",
    "BASELINE_MODEL_PATH = baseline_dataset_name + \"_evaluated_\" + MODEL_NAME\n",
    "\n",
    "if not os.path.exists(EVALUATED_MODEL_PATH):\n",
    "    dataset.save_to_disk(EVALUATED_MODEL_PATH)\n",
    "if not os.path.exists(BASELINE_MODEL_PATH):\n",
    "    baseline_dataset = load_dataset(baseline_dataset_name, subset)[\"test\"]\n",
    "    baseline_dataset.save_to_disk(BASELINE_MODEL_PATH)"
   ],
   "id": "62b73412d8b897a7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1319 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "663c102b738b4882a13a5a7e3663014e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T10:11:39.791933Z",
     "start_time": "2025-01-23T10:11:39.771495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "from datasets import Dataset\n",
    "import requests\n",
    "\n",
    "\n",
    "# Helper Functions\n",
    "def create_chat_messages(question, sys_msg):\n",
    "    \"\"\"\n",
    "    Create a formatted list of chat messages for the chat model.\n",
    "    \"\"\"\n",
    "    user_prompt = f\"{question}\\n\" + \"\\nCalculations:\"\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": sys_msg},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "\n",
    "def query_vllm_api(payload):\n",
    "    \"\"\"\n",
    "    Send a query to the VLLM API and return the response.\n",
    "    \"\"\"\n",
    "    response = requests.post(BASE_URL, json=payload, headers=HEADERS, timeout=120)\n",
    "    response.raise_for_status()  # Raise an error for HTTP issues\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def evaluate_question(entry):\n",
    "    # Step 1: Generate reasoning (CoT) response\n",
    "    sys_msg = \"The following are math questions. Think step by step. State your final answer at the end of your calculations.\"\n",
    "    question = entry[\"question\"]\n",
    "    messages = create_chat_messages(question, sys_msg)\n",
    "\n",
    "    cot_payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 2000,\n",
    "        \"temperature\": 0.0,\n",
    "    }\n",
    "\n",
    "    cot_response = query_vllm_api(cot_payload)\n",
    "    if \"object\" in cot_response.keys() and cot_response[\"object\"] == \"error\":\n",
    "        raise Exception(cot_response[\"message\"])\n",
    "\n",
    "    cot_text = cot_response[\"choices\"][0][\"message\"][\"content\"].strip()  # Extract CoT reasoning\n",
    "    gen_answer = extract_answer(cot_text)\n",
    "    entry[\"generated_answer\"] = gen_answer\n",
    "    entry[\"generated_cot\"] = cot_text\n",
    "    return entry\n",
    "\n",
    "\n",
    "def extract_answer(gen_answer):\n",
    "    # Remove commas so for example 5,000 becomes 5000\n",
    "    model_resp = gen_answer.replace(\",\", \"\")\n",
    "    # Find the last number\n",
    "    extracted_num = re.findall(r\"-?\\d+\\.?\\d*\", model_resp)[-1]\n",
    "    # Use float to ensure 3.0 and 3 are the same.\n",
    "    return str(float(extracted_num))\n",
    "\n",
    "\n",
    "def is_correct(entry):\n",
    "    \"\"\"\n",
    "    Determines if the choice with the lowest log probability corresponds to the correct answer.\n",
    "\n",
    "    Args:\n",
    "        entry (dict): A dictionary containing the question, choices, answer index, and logprobs.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the option with the lowest logprob matches the correct answer index, False otherwise.\n",
    "    \"\"\"\n",
    "    # Extract logprobs and the correct answer index\n",
    "    gen_answer = entry['generated_answer']\n",
    "    if gen_answer == \"\":\n",
    "        return False\n",
    "    answer = extract_answer(entry['answer'])\n",
    "\n",
    "    return answer == gen_answer\n",
    "\n",
    "\n",
    "def process_dataset(dataset: Dataset, numproc=1):\n",
    "    \"\"\"\n",
    "    Process the dataset using Dataset.map.\n",
    "    \"\"\"\n",
    "\n",
    "    def process_entry(entry):\n",
    "        if \"generated_answer\" in entry.keys() and not entry[\"generated_answer\"] == \"\":\n",
    "            return entry\n",
    "        try:\n",
    "            return evaluate_question(entry)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing entry: {entry}, Exception: {e}\")\n",
    "            entry[\"generated_answer\"] = \"\"\n",
    "            entry[\"generated_cot\"] = \"\"\n",
    "            return entry\n",
    "\n",
    "    return dataset.map(process_entry, with_indices=False, num_proc=numproc)"
   ],
   "id": "c60fc0802c475748",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T10:11:39.812178Z",
     "start_time": "2025-01-23T10:11:39.799712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def update_dataset(dataset, is_baseline=False):\n",
    "    # Save the updated dataset to a temporary location\n",
    "    temp_path = \"temp\"\n",
    "    dataset.save_to_disk(temp_path)\n",
    "\n",
    "    # Overwrite the original dataset directory\n",
    "    import shutil\n",
    "    original_path = EVALUATED_MODEL_PATH if is_baseline == False else BASELINE_MODEL_PATH\n",
    "\n",
    "    # Remove the old dataset and replace it with the new one\n",
    "    shutil.rmtree(original_path)  # Remove the old dataset directory\n",
    "    shutil.move(temp_path, original_path)"
   ],
   "id": "e0ee2b6c396f28dd",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T10:14:42.404847Z",
     "start_time": "2025-01-23T10:14:28.554095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main(is_continue=False, is_baseline=False, numproc=1):\n",
    "    \"\"\"\n",
    "    Main function to evaluate the dataset asynchronously.\n",
    "    \"\"\"\n",
    "    if is_baseline:\n",
    "        selected_dataset = load_from_disk(BASELINE_MODEL_PATH)\n",
    "    elif is_continue:\n",
    "        selected_dataset = load_from_disk(EVALUATED_MODEL_PATH)\n",
    "    else:\n",
    "        selected_dataset = dataset\n",
    "    # Process the dataset asynchronously\n",
    "    processed_dataset = process_dataset(selected_dataset, numproc)\n",
    "\n",
    "    # Save the updated dataset\n",
    "    update_dataset(processed_dataset, is_baseline)\n",
    "\n",
    "\n",
    "# Run the script\n",
    "main(True, True, 200)"
   ],
   "id": "6c05b4e127512852",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map (num_proc=200):   0%|          | 0/1319 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3bd7bb60423a4d529eef3bcaa087ad63"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1319 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21c881dc6d154b918e411c2bef3853dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T10:14:44.495019Z",
     "start_time": "2025-01-23T10:14:44.188231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from converter.converter import save_value_to_json\n",
    "\n",
    "for subset in [\"addition\", \"lexicon\", \"syntax\", \"\", \"naive\", \"typo\", \"scramble\"]:\n",
    "    if subset == \"\":\n",
    "        EVALUATED_MODEL_PATH = dataset_name + \"_main\" + \"_evaluated_\" + MODEL_NAME\n",
    "        subset = \"our_baseline\"\n",
    "    else:\n",
    "        EVALUATED_MODEL_PATH = dataset_name + \"_main_\" + subset + \"_evaluated_\" + MODEL_NAME\n",
    "    if os.path.exists(EVALUATED_MODEL_PATH):\n",
    "        selected_dataset = load_from_disk(EVALUATED_MODEL_PATH)\n",
    "        print(EVALUATED_MODEL_PATH)\n",
    "        print(selected_dataset)\n",
    "        score = [is_correct(result) for result in selected_dataset]\n",
    "        score = sum(score) / len(score)\n",
    "        save_value_to_json(subset, score, MODEL_NAME)\n",
    "        print(subset, \"accuracy\", score)\n",
    "    else:\n",
    "        print(\"skipping\", EVALUATED_MODEL_PATH)"
   ],
   "id": "d6511a8a3f86cbc0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LFrancis/GSM8k-NoOp-Plus_main_addition_evaluated_meta-llama/Meta-Llama-3-8B-Instruct\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'generated_answer', 'generated_cot'],\n",
      "    num_rows: 1319\n",
      "})\n",
      "addition accuracy 0.6618650492797574\n",
      "LFrancis/GSM8k-NoOp-Plus_main_lexicon_evaluated_meta-llama/Meta-Llama-3-8B-Instruct\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'generated_answer', 'generated_cot'],\n",
      "    num_rows: 1319\n",
      "})\n",
      "lexicon accuracy 0.6391205458680819\n",
      "LFrancis/GSM8k-NoOp-Plus_main_syntax_evaluated_meta-llama/Meta-Llama-3-8B-Instruct\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'generated_answer', 'generated_cot'],\n",
      "    num_rows: 1319\n",
      "})\n",
      "syntax accuracy 0.7065959059893859\n",
      "LFrancis/GSM8k-NoOp-Plus_main_evaluated_meta-llama/Meta-Llama-3-8B-Instruct\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'generated_answer', 'generated_cot'],\n",
      "    num_rows: 1319\n",
      "})\n",
      "our_baseline accuracy 0.7505686125852918\n",
      "LFrancis/GSM8k-NoOp-Plus_main_naive_evaluated_meta-llama/Meta-Llama-3-8B-Instruct\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'generated_answer', 'generated_cot'],\n",
      "    num_rows: 1319\n",
      "})\n",
      "naive accuracy 0.7490523123578469\n",
      "LFrancis/GSM8k-NoOp-Plus_main_typo_evaluated_meta-llama/Meta-Llama-3-8B-Instruct\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'generated_answer', 'generated_cot'],\n",
      "    num_rows: 1319\n",
      "})\n",
      "typo accuracy 0.6595905989385898\n",
      "LFrancis/GSM8k-NoOp-Plus_main_scramble_evaluated_meta-llama/Meta-Llama-3-8B-Instruct\n",
      "Dataset({\n",
      "    features: ['question', 'answer', 'generated_answer', 'generated_cot'],\n",
      "    num_rows: 1319\n",
      "})\n",
      "scramble accuracy 0.5496588324488249\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T10:15:10.689107Z",
     "start_time": "2025-01-23T10:15:10.602965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "baseline_dataset = load_from_disk(BASELINE_MODEL_PATH)\n",
    "score = [is_correct(result) for result in baseline_dataset]\n",
    "score = sum(score) / len(score)\n",
    "save_value_to_json(\"baseline\", score, MODEL_NAME)\n",
    "print(\"Baseline Accuracy\", score)"
   ],
   "id": "57d06cdc2ef4c6ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy 0.7513267626990144\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T12:13:14.333623Z",
     "start_time": "2025-01-21T12:13:14.323874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "selected_dataset = load_from_disk(dataset_name + \"_main_addition_evaluated_\" + MODEL_NAME)\n",
    "selected_dataset[0][\"generated_cot\"]"
   ],
   "id": "47d01683370245ab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To find out how much Janet makes every day at the farmers' market, we need to calculate the number of eggs she has left after eating and baking, and then multiply that number by the price she sells each egg for.\\n\\n1. Calculate the total number of eggs laid by the ducks per day: \\n   Total eggs per day = 16\\n\\n2. Calculate the number of eggs Janet eats for breakfast:\\n   Eggs eaten for breakfast = 3\\n\\n3. Calculate the number of eggs Janet bakes for her friends:\\n   Eggs baked for friends = 4\\n\\n4. Calculate the total number of eggs Janet uses:\\n   Total eggs used = Eggs eaten for breakfast + Eggs baked for friends\\n   Total eggs used = 3 + 4\\n   Total eggs used = 7\\n\\n5. Calculate the number of eggs Janet has left:\\n   Eggs left = Total eggs per day - Total eggs used\\n   Eggs left = 16 - 7\\n   Eggs left = 9\\n\\n6. Calculate the amount Janet makes by selling the eggs:\\n   Amount made = Eggs left * Price per egg\\n   Amount made = 9 * $2\\n   Amount made = $18\\n\\nTherefore, Janet makes $18 every day at the farmers' market.\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T12:13:15.403950Z",
     "start_time": "2025-01-21T12:13:15.397306Z"
    }
   },
   "cell_type": "code",
   "source": "baseline_dataset[0][\"question\"]",
   "id": "87ece965233f60a2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\""
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T10:44:45.743445Z",
     "start_time": "2025-01-21T10:44:45.742245Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "425570df70200025",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
