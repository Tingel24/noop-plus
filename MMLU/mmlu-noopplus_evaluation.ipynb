{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T15:11:54.620929Z",
     "start_time": "2025-01-26T15:11:51.052173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os.path\n",
    "\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\")\n",
    "# Load MMLU Dataset\n",
    "dataset_name = \"LFrancis/MMLU-NoOp-Plus\"\n",
    "baseline_dataset_name = \"cais/mmlu\"\n",
    "subset = \"all_addition\"\n",
    "dataset = load_dataset(dataset_name, subset)[\"train\"]\n",
    "\n",
    "# VLLM API Configuration\n",
    "BASE_URL = \"http://134.76.18.30:8080/v1/chat/completions\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\", \"Authorization\": \"Bearer \" + os.getenv(\"VLLM_API_KEY\")}\n",
    "MODEL_NAME = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "EVALUATED_MODEL_PATH = dataset_name + \"_\" + subset + \"_evaluated_\" + MODEL_NAME\n",
    "BASELINE_MODEL_PATH = baseline_dataset_name + \"_evaluated_\" + MODEL_NAME\n",
    "if not os.path.exists(EVALUATED_MODEL_PATH):\n",
    "    dataset.save_to_disk(EVALUATED_MODEL_PATH)\n",
    "#dataset.save_to_disk(EVALUATED_MODEL_PATH)\n",
    "options = [\"A\", \"B\", \"C\", \"D\"]"
   ],
   "id": "62b73412d8b897a7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/4.73M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "762e50c4865d403383787a5067940175"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating train split:   0%|          | 0/14042 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "84d19017837d4f6f9549a789adfa59ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T15:11:54.641250Z",
     "start_time": "2025-01-26T15:11:54.632192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import Dataset\n",
    "import requests\n",
    "\n",
    "\n",
    "# Helper Functions\n",
    "def create_chat_messages(question, choices, subject, sys_msg):\n",
    "    \"\"\"\n",
    "    Create a formatted list of chat messages for the chat model.\n",
    "    \"\"\"\n",
    "    user_prompt = f\"{question}\\n\" + \"\\n\".join(\n",
    "        [f\"{opt}. {choice}\" for opt, choice in zip(options, choices)]\n",
    "    ) + \"\\nAnswer:\"\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": sys_msg.format(subject)},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "\n",
    "def query_vllm_api(payload):\n",
    "    \"\"\"\n",
    "    Send a query to the VLLM API and return the response.\n",
    "    \"\"\"\n",
    "    response = requests.post(BASE_URL, json=payload, headers=HEADERS, timeout=120)\n",
    "    response.raise_for_status()  # Raise an error for HTTP issues\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def evaluate_question(entry):\n",
    "    # Step 1: Generate reasoning (CoT) response\n",
    "    sys_msg = \"The following are multiple choice questions (with answers) about {}.\"\n",
    "    question, choices, subject = entry[\"question\"], entry[\"choices\"], entry[\"subject\"]\n",
    "\n",
    "    messages = create_chat_messages(question, choices, subject, sys_msg)\n",
    "\n",
    "    cot_payload = {\n",
    "        \"model\": MODEL_NAME,  # Specify model\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 200,\n",
    "        \"temperature\": 0.0,\n",
    "    }\n",
    "\n",
    "    cot_response = query_vllm_api(cot_payload)\n",
    "    if \"object\" in cot_response.keys() and cot_response[\"object\"] == \"error\":\n",
    "        raise Exception(cot_response[\"message\"])\n",
    "\n",
    "    cot_text = cot_response[\"choices\"][0][\"message\"][\"content\"].strip()  # Extract CoT reasoning\n",
    "\n",
    "    # Step 2: Calculate logprobs for each choice\n",
    "    final_prompt = f\"{cot_text}\\n\" + \"\\n\".join(\n",
    "        [f\"{opt}. {choice}\" for opt, choice in zip(options, choices)]\n",
    "    ) + \"Final Answer: \"\n",
    "    logprobs = {}\n",
    "    for idx, option in enumerate(options):\n",
    "        choice_messages = [\n",
    "            *messages,\n",
    "            {\"role\": \"system\", \"content\": sys_msg.format(subject)},\n",
    "            {\"role\": \"user\", \"content\": final_prompt + f\" {option}\"}\n",
    "        ]\n",
    "        choice_payload = {\n",
    "            \"model\": MODEL_NAME,\n",
    "            \"messages\": choice_messages,\n",
    "            \"max_tokens\": 1,\n",
    "            \"temperature\": 0.0,\n",
    "            \"prompt_logprobs\": 0\n",
    "        }\n",
    "        choice_response = query_vllm_api(choice_payload)\n",
    "        if \"prompt_logprobs\" not in choice_response:\n",
    "            raise Exception(f\"No prompt logprobs found for {option}\")\n",
    "        logprobs[option] = list(choice_response[\"prompt_logprobs\"][-6].values())[0][\"logprob\"]\n",
    "    entry[\"logprobs\"] = logprobs\n",
    "    return entry\n",
    "\n",
    "\n",
    "def is_correct(entry):\n",
    "    \"\"\"\n",
    "    Determines if the choice with the lowest log probability corresponds to the correct answer.\n",
    "\n",
    "    Args:\n",
    "        entry (dict): A dictionary containing the question, choices, answer index, and logprobs.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the option with the lowest logprob matches the correct answer index, False otherwise.\n",
    "    \"\"\"\n",
    "    # Extract logprobs and the correct answer index\n",
    "    logprobs = entry['logprobs']\n",
    "    if logprobs == {} or logprobs == {'A': None, 'B': None, 'C': None, 'D': None}:\n",
    "        print(\"skip \", end=\"\")\n",
    "        return False\n",
    "    correct_answer_index = entry['answer']\n",
    "\n",
    "    # Find the key (A, B, C, D) with the lowest logprob\n",
    "    highest_logprob_option = max(logprobs, key=logprobs.get)\n",
    "\n",
    "    # Map the key to its corresponding index (0 for 'A', 1 for 'B', etc.)\n",
    "    options = [\"A\", \"B\", \"C\", \"D\"]\n",
    "    highest_logprob_index = options.index(highest_logprob_option)\n",
    "\n",
    "    # Check if the lowest logprob index matches the correct answer index\n",
    "    return highest_logprob_index == correct_answer_index\n",
    "\n",
    "\n",
    "def process_dataset(dataset: Dataset, numproc=1):\n",
    "    \"\"\"\n",
    "    Process the dataset using Dataset.map.\n",
    "    \"\"\"\n",
    "\n",
    "    def process_entry(entry):\n",
    "        if \"logprobs\" in entry.keys():\n",
    "            # entry has been touched\n",
    "            if  entry[\"logprobs\"] != {} and entry[\"logprobs\"] != {'A': None, 'B': None, 'C': None, 'D': None}:\n",
    "                return entry\n",
    "        try:\n",
    "            return evaluate_question(entry)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing entry: {entry}, Exception: {e}\")\n",
    "            entry[\"logprobs\"] = {}\n",
    "            return entry\n",
    "\n",
    "    return dataset.map(process_entry, with_indices=False, num_proc=numproc)"
   ],
   "id": "c60fc0802c475748",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T15:11:54.648571Z",
     "start_time": "2025-01-26T15:11:54.646548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def update_dataset(dataset, is_baseline=False):\n",
    "    # Save the updated dataset to a temporary location\n",
    "    temp_path = \"temp\"\n",
    "    dataset.save_to_disk(temp_path)\n",
    "\n",
    "    # Overwrite the original dataset directory\n",
    "    import shutil\n",
    "    original_path = EVALUATED_MODEL_PATH if is_baseline == False else BASELINE_MODEL_PATH\n",
    "\n",
    "    # Remove the old dataset and replace it with the new one\n",
    "    shutil.rmtree(original_path)  # Remove the old dataset directory\n",
    "    shutil.move(temp_path, original_path)"
   ],
   "id": "e0ee2b6c396f28dd",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T15:12:00.076339Z",
     "start_time": "2025-01-26T15:11:56.476277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main(is_continue=False, is_baseline=False, numproc=1):\n",
    "    \"\"\"\n",
    "    Main function to evaluate the dataset asynchronously.\n",
    "    \"\"\"\n",
    "    if is_baseline:\n",
    "        selected_dataset = load_from_disk(BASELINE_MODEL_PATH)\n",
    "    elif is_continue:\n",
    "        selected_dataset = load_from_disk(EVALUATED_MODEL_PATH)\n",
    "    else:\n",
    "        selected_dataset = dataset\n",
    "    # Process the dataset asynchronously\n",
    "    processed_dataset = process_dataset(selected_dataset, numproc)\n",
    "\n",
    "    # Save the updated dataset\n",
    "    update_dataset(processed_dataset, is_baseline)\n",
    "\n",
    "\n",
    "# Run the script\n",
    "main(True, False, 1)"
   ],
   "id": "6c05b4e127512852",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/14042 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f5df03b7e1af46c685316d0fd66556ca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/14042 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d7cd21be783944008ccefafd9aecb15f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T15:11:35.916500Z",
     "start_time": "2025-01-26T15:11:33.260899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from converter.converter import save_value_to_json\n",
    "\n",
    "# Save or process results as needed\n",
    "for s in [\"addition\", \"lexicon\", \"syntax\", \"\", \"naive\", \"typo\", \"scramble\"]:\n",
    "    if s == \"\":\n",
    "        EVALUATED_MODEL_PATH = dataset_name + \"_evaluated_\" + MODEL_NAME\n",
    "        s = \"our_baseline\"\n",
    "    else:\n",
    "        EVALUATED_MODEL_PATH = dataset_name + \"_all_\" + s + \"_evaluated_\" + MODEL_NAME\n",
    "    if os.path.exists(EVALUATED_MODEL_PATH):\n",
    "        selected_dataset = load_from_disk(EVALUATED_MODEL_PATH)\n",
    "        print(selected_dataset)\n",
    "        score = [is_correct(result) for result in selected_dataset]\n",
    "        score = sum(score) / len(score)\n",
    "        save_value_to_json(s, score, MODEL_NAME)\n",
    "        print(s, \"accuracy\", score)"
   ],
   "id": "d6511a8a3f86cbc0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'subject', 'choices', 'answer', 'logprobs'],\n",
      "    num_rows: 14042\n",
      "})\n",
      "skip addition accuracy 0.6734083463894032\n",
      "Dataset({\n",
      "    features: ['question', 'subject', 'choices', 'answer', 'logprobs'],\n",
      "    num_rows: 14042\n",
      "})\n",
      "skip skip skip skip skip skip skip skip skip lexicon accuracy 0.6826662868537245\n",
      "Dataset({\n",
      "    features: ['question', 'subject', 'choices', 'answer', 'logprobs'],\n",
      "    num_rows: 14042\n",
      "})\n",
      "skip syntax accuracy 0.6845890898732374\n",
      "Dataset({\n",
      "    features: ['question', 'subject', 'choices', 'answer', 'logprobs'],\n",
      "    num_rows: 14042\n",
      "})\n",
      "skip skip skip our_baseline accuracy 0.7028913260219342\n",
      "Dataset({\n",
      "    features: ['question', 'subject', 'choices', 'answer', 'logprobs'],\n",
      "    num_rows: 14042\n",
      "})\n",
      "skip skip naive accuracy 0.6786782509614016\n",
      "Dataset({\n",
      "    features: ['question', 'subject', 'choices', 'answer', 'logprobs'],\n",
      "    num_rows: 14042\n",
      "})\n",
      "skip skip skip typo accuracy 0.6442814413901153\n",
      "Dataset({\n",
      "    features: ['question', 'subject', 'choices', 'answer', 'logprobs'],\n",
      "    num_rows: 14042\n",
      "})\n",
      "scramble accuracy 0.5267055974932345\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T12:15:47.068585Z",
     "start_time": "2025-01-26T12:15:46.735031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "baseline_dataset = load_from_disk(BASELINE_MODEL_PATH)\n",
    "score = [is_correct(result) for result in baseline_dataset]\n",
    "score = sum(score) / len(score)\n",
    "save_value_to_json(\"baseline\", score, MODEL_NAME)\n",
    "print(\"Baseline Accuracy\", score)"
   ],
   "id": "57d06cdc2ef4c6ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy 0.7026776812419884\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T12:15:47.082541Z",
     "start_time": "2025-01-26T12:15:47.080482Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ee329def26a8c925",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
