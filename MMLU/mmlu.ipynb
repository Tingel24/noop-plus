{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "https://github.com/openai/evals/blob/main/examples/mmlu.ipynb"
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an MMLU Eval\n",
    "\n",
    "This notebook shows how to:\n",
    "- Build and run an eval\n",
    "- Load the results and into a Pandas Dataframe\n",
    "\n",
    "We use the `evals.elsuite.basic.match:Match` Eval class here to check whether new completions match the correct answer. Under the hood, it will generate a completion with the choice of model for each prompt, check if the completion matches the true answer, then logs a result."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T12:48:07.011370Z",
     "start_time": "2024-12-03T12:48:03.808596Z"
    }
   },
   "source": [
    "from openai import OpenAI\n",
    "from datasets import load_dataset\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"asdasdasd\",\n",
    "    base_url=\"http://134.76.18.30:8085/v1\"\n",
    ")\n",
    "modified_dataset_name = \"MMLU-NoOp-Plus\"\n",
    "\n",
    "hf_username = \"LFrancis\"\n",
    "repo_id = f\"{hf_username}/{modified_dataset_name}\"\n",
    "dataset = load_dataset(repo_id, \"all\")[\"train\"]\n",
    "dataset"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'subject', 'choices', 'answer'],\n",
       "    num_rows: 14042\n",
       "})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T12:48:08.454112Z",
     "start_time": "2024-12-03T12:48:08.440047Z"
    }
   },
   "source": [
    "sys_msg = \"The following are multiple choice questions (with answers) about {}.\"\n",
    "\n",
    "\n",
    "def create_chat_prompt(question, choices, subject):\n",
    "    options = [\"A\", \"B\", \"C\", \"D\"]\n",
    "\n",
    "    user_prompt = f\"{question}\\n\" + \"\\n\".join(\n",
    "        [f\"{option}. {choice}\" for option, choice in zip(options, choices)]) + \"\\nAnswer:\"\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": sys_msg.format(subject)},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "async with session.post(self.generate_url, json=payload) as response:\n",
    "    output = await response.json()\n",
    "    return output[\"details\"][\"prefill\"]"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T12:54:52.046250Z",
     "start_time": "2024-12-03T12:54:51.969323Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for entry in dataset.take(1):\n",
    "    prompt = create_chat_prompt(entry[\"question\"], entry[\"choices\"], entry[\"subject\"])\n",
    "\n",
    "    payload = {\n",
    "                    \"inputs\": self.tokenizer.apply_chat_template(\n",
    "                        messages, tokenize=False, add_generation_prompt=True\n",
    "                    ),\n",
    "                    \"parameters\": {\n",
    "                        \"decoder_input_details\": True,\n",
    "                        \"max_new_tokens\": 1,\n",
    "                        \"temperature\": 0.0,\n",
    "                    },\n",
    "                }\n",
    "   for choice in choices:\n",
    "                payload = copy.deepcopy(base_payload)\n",
    "                payload[\"inputs\"] += choice\n",
    "                tasks.append(\n",
    "                    asyncio.create_task(_aloglikelihood_inner(session, payload))\n",
    "                )\n",
    "\n",
    "\n",
    "    print(response)"
   ],
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Completions.create() got an unexpected keyword argument 'decoder_input_details'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[48], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m entry \u001B[38;5;129;01min\u001B[39;00m dataset\u001B[38;5;241m.\u001B[39mtake(\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m      2\u001B[0m     prompt \u001B[38;5;241m=\u001B[39m create_chat_prompt(entry[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mquestion\u001B[39m\u001B[38;5;124m\"\u001B[39m], entry[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchoices\u001B[39m\u001B[38;5;124m\"\u001B[39m], entry[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msubject\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m----> 3\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mclient\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchat\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompletions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43masdasd\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmessages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprompt\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtop_logprobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlogprobs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecoder_input_details\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_new_token\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28mprint\u001B[39m(response)\n",
      "File \u001B[0;32m~/noop-plus/.venv/lib/python3.10/site-packages/openai/_utils/_utils.py:277\u001B[0m, in \u001B[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    275\u001B[0m             msg \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing required argument: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquote(missing[\u001B[38;5;241m0\u001B[39m])\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    276\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(msg)\n\u001B[0;32m--> 277\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: Completions.create() got an unexpected keyword argument 'decoder_input_details'"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oss_evals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
