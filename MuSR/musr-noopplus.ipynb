{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Setup model connection\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "from converter.converter import *\n",
    "\n",
    "load_dotenv(\"../.env\")\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"VLLM_API_KEY\"),\n",
    "    base_url=\"http://134.76.18.30:8098/v1\"\n",
    ")\n",
    "model = \"meta-llama/Llama-3.3-70B-Instruct\""
   ],
   "id": "aada7471ad0a3881",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load original dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d57750e572255fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "\n",
    "# Load spaCy for POS tagging\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "tqdm.pandas()\n",
    "\n",
    "dataset = load_dataset(\"TAUR-Lab/MuSR\")\n",
    "modified_dataset_name = \"MuSR-NoOp-Plus\"\n",
    "\n",
    "hf_username = \"LFrancis\"\n",
    "repo_id = f\"{hf_username}/{modified_dataset_name}\"\n",
    "\n",
    "dataset_dict = DatasetDict(dataset)\n",
    "dataset"
   ],
   "id": "6b49ccc083448f2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Paraphrase Type: Naive Addition"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2d4da176f5705ba"
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "code",
   "source": [
    "for subset in dataset.keys():\n",
    "    dataset_dict[subset + \"_naive\"] = convert_naive(pd.DataFrame(dataset[subset]), question_column=\"narrative\",\n",
    "                                                    subject_list_column=\"choices\")\n",
    "dataset_dict.keys()"
   ],
   "id": "5a6a869abf2d97c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "upload(dataset_dict, repo_id)",
   "id": "b7c4cb09b36bc9eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Paraphrase Type: Addition",
   "id": "6f70d4a9110a3bab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "custom_preprompt = \"Give me one additional sentence to this story that has no direct effect on the storyline. The sentence should include one of the characters. Example additional sentences might focus on unnecessary details, add unnecessary information about one of the characters past or thoughts. Only output exactly only the additional sentence and nothing else, the output will be copy/pasted as is. It is extremely important that the sentence does not effect the storyline. The sentence should try to confuse an inattentive detective.\"",
   "id": "7766a0fbc7963651",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for subset in dataset.keys():\n",
    "    dataset_dict[subset + \"_addition\"] = convert_additional(pd.DataFrame(dataset[subset]), client, model, nlp,\n",
    "                                                            custom_preprompt=custom_preprompt,\n",
    "                                                            question_column=\"narrative\")\n",
    "dataset_dict.keys()"
   ],
   "id": "6f95971adc692c8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "upload(dataset_dict, repo_id)",
   "id": "d837f20d537f24c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Paraphrase Type: Lexicon-Changes\n",
   "id": "3af5f01884e9f923"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for subset in dataset.keys():\n",
    "    dataset_dict[subset + \"_lexicon\"] = convert_lexicon(pd.DataFrame(dataset[subset]), client, model, nlp,\n",
    "                                                        question_column=\"narrative\")\n",
    "dataset_dict.keys()"
   ],
   "id": "d0b5d00a4ba54e62",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [57:38<00:00, 13.83s/it] \n",
      "100%|██████████| 256/256 [57:27<00:00, 13.47s/it] \n",
      "100%|██████████| 250/250 [23:17<00:00,  5.59s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['murder_mysteries', 'object_placements', 'team_allocation', 'murder_mysteries_lexicon', 'object_placements_lexicon', 'team_allocation_lexicon'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-23T19:19:00.520939Z",
     "start_time": "2025-01-23T19:18:47.676344Z"
    }
   },
   "cell_type": "code",
   "source": "upload(dataset_dict, repo_id)",
   "id": "b58adeed585c7236",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading murder_mysteries\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3782d738f53541b79a2db0335401d62e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c3afbded86546b98803082169168e0b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading object_placements\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b1dc497115154ff79ab1bc6ab1b92951"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ded2fd68d06485e992e96157f57966b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading team_allocation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8d5e70e535484f799187f24767d7c125"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf93c51c42e54de3a1dd8abe8b243f85"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading murder_mysteries_lexicon\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14628f72271d436d9b1cce10b5db6eae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6002e76581c44de181720173b452d516"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading object_placements_lexicon\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0579a4be9d7c4133b85914743cbe0a92"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "74de686b4d2e4326a72a1b676d525b73"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/10.8k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5e0fd05ac6774af29c3da7be22e94a05"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading team_allocation_lexicon\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2f94d03e19ed4d14a8ae9c89ff1ff8db"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "668862faa59b4cedbb987aea1fb63b21"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "README.md:   0%|          | 0.00/10.8k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ab1f0dfdc0c34735bcf162edb537839b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Paraphrase Type: Syntax-Changes\n",
   "id": "9311a162e96e675"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for subset in dataset.keys():\n",
    "    dataset_dict[subset + \"_syntax\"] = convert_syntax(pd.DataFrame(dataset[subset]), nlp, question_column=\"narrative\")\n",
    "dataset_dict.keys()"
   ],
   "id": "5caeffa2a318920",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "upload(dataset_dict, repo_id)",
   "id": "e9e2a942adb9760",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Paraphrase Type: Typo",
   "id": "8861dd66fc85daf1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for subset in dataset.keys():\n",
    "    dataset_dict[subset + \"_typo\"] = convert_typo(pd.DataFrame(dataset[subset]), question_column=\"narrative\")\n",
    "dataset_dict.keys()"
   ],
   "id": "bc2d943afe9bfed3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "upload(dataset_dict, repo_id)",
   "id": "687645dd37282e6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Paraphrase Type: Scramble",
   "id": "5f490c7541d643bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for subset in dataset.keys():\n",
    "    dataset_dict[subset + \"_scramble\"] = convert_scramble(pd.DataFrame(dataset[subset]),nlp, question_column=\"narrative\")\n",
    "dataset_dict.keys()"
   ],
   "id": "6fa143ec6224a04e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "upload(dataset_dict, repo_id)",
   "id": "ecade1a06b2d4087",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "25b8905b4b1f782a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
